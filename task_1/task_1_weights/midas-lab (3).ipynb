{"metadata":{"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Moving to directory where data is stored","metadata":{}},{"cell_type":"code","source":"\ncd train-1 ","metadata":{"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"/kaggle/input/train-1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Importing the required libraries**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow.keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense,Conv2D,Flatten,Dropout,MaxPool2D,AvgPool2D,BatchNormalization,Activation\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential,Model\nfrom tensorflow.keras.applications import InceptionV3","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Data flow pipeline with some noise additions (brightness change, zoom) and 20% test data","metadata":{}},{"cell_type":"code","source":"datagen= ImageDataGenerator(\nzoom_range=0.15,\nbrightness_range = [0.3,1.4],\nvalidation_split=0.20)\ntrain_it=datagen.flow_from_directory('train',class_mode='categorical',batch_size=31,target_size=(240,180),shuffle=True,color_mode='grayscale',subset='training')\ntest_it= datagen.flow_from_directory('train',class_mode='categorical',batch_size=31,target_size=(240,180),shuffle=True,color_mode='grayscale',subset='validation')","metadata":{"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Found 1984 images belonging to 62 classes.\nFound 496 images belonging to 62 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Creating variable learning rate with initial rate= 0.001, decay= 0.001/200 and momentum of 0.9","metadata":{}},{"cell_type":"code","source":"lr_schedule = tensorflow.keras.optimizers.SGD(\n    lr=0.001,\n    decay= 0.001/200,\n    momentum=0.9)","metadata":{"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# Proposed Model Architecture (Main Model)","metadata":{}},{"cell_type":"markdown","source":"# **The reference for the structure of the model below is inspired from from VGG-16 model with some variations like addition of batch normalization and dropout layer to avoid overfitting (this was the case when I used the below architecture without the use of batch normalization layer) and improves the training speed. The input size considered here is larger(240x180) than mnist hand written data size as the accuracy was only around 76% (shown after this model) after reducing it to 28x28. The activation function used is relu with softmax function at the last dense layer.**","metadata":{}},{"cell_type":"code","source":"model=Sequential()\nmodel.add(Conv2D(64, (3, 3), padding=\"same\",input_shape=(240,180,1)))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(256, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(512, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(512, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(250))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\nmodel.add(Dense(62))\nmodel.add(Activation(\"softmax\"))","metadata":{"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Coding was done on kaggle notebook. Due to limited session time I have to save the model weights(after1st training) and again retrain the model. Each time model was trained for 200 epochs. Below the model weights are being loaded for second time training. The model was trained for 400 epochs (i.e 2 times)**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nmodel=load_model('../weights-final/IIIT (7).h5')","metadata":{"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Compiling the model","metadata":{}},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer= lr_schedule)\n","metadata":{"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# Saving the weights with max val accuracy","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\nfilepath='../../working/IIIT.h5'\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]","metadata":{"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"# Model training for the 2nd time ","metadata":{}},{"cell_type":"code","source":"model.fit(train_it,steps_per_epoch=int(1984/31),epochs=200,validation_data=test_it,validation_steps=int(496/31),callbacks=callbacks_list)\n","metadata":{"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Epoch 1/200\n64/64 [==============================] - 58s 862ms/step - loss: 4.8412 - accuracy: 0.0226 - val_loss: 5.3828 - val_accuracy: 0.0202\n\nEpoch 00001: val_accuracy improved from -inf to 0.02016, saving model to ../../working/IIIT.h5\nEpoch 2/200\n64/64 [==============================] - 54s 851ms/step - loss: 3.9769 - accuracy: 0.0607 - val_loss: 3.5815 - val_accuracy: 0.1431\n\nEpoch 00002: val_accuracy improved from 0.02016 to 0.14315, saving model to ../../working/IIIT.h5\nEpoch 3/200\n64/64 [==============================] - 54s 838ms/step - loss: 3.4049 - accuracy: 0.1448 - val_loss: 2.9208 - val_accuracy: 0.2802\n\nEpoch 00003: val_accuracy improved from 0.14315 to 0.28024, saving model to ../../working/IIIT.h5\nEpoch 4/200\n64/64 [==============================] - 54s 844ms/step - loss: 2.8748 - accuracy: 0.2731 - val_loss: 2.5803 - val_accuracy: 0.3730\n\nEpoch 00004: val_accuracy improved from 0.28024 to 0.37298, saving model to ../../working/IIIT.h5\nEpoch 5/200\n64/64 [==============================] - 53s 830ms/step - loss: 2.4985 - accuracy: 0.3521 - val_loss: 2.3675 - val_accuracy: 0.3972\n\nEpoch 00005: val_accuracy improved from 0.37298 to 0.39718, saving model to ../../working/IIIT.h5\nEpoch 6/200\n64/64 [==============================] - 54s 843ms/step - loss: 2.1421 - accuracy: 0.4775 - val_loss: 2.1590 - val_accuracy: 0.4355\n\nEpoch 00006: val_accuracy improved from 0.39718 to 0.43548, saving model to ../../working/IIIT.h5\nEpoch 7/200\n64/64 [==============================] - 54s 853ms/step - loss: 1.8574 - accuracy: 0.5098 - val_loss: 1.8869 - val_accuracy: 0.5262\n\nEpoch 00007: val_accuracy improved from 0.43548 to 0.52621, saving model to ../../working/IIIT.h5\nEpoch 8/200\n64/64 [==============================] - 54s 841ms/step - loss: 1.6056 - accuracy: 0.5708 - val_loss: 1.8695 - val_accuracy: 0.4940\n\nEpoch 00008: val_accuracy did not improve from 0.52621\nEpoch 9/200\n64/64 [==============================] - 54s 842ms/step - loss: 1.4139 - accuracy: 0.6385 - val_loss: 1.6275 - val_accuracy: 0.5706\n\nEpoch 00009: val_accuracy improved from 0.52621 to 0.57056, saving model to ../../working/IIIT.h5\nEpoch 10/200\n64/64 [==============================] - 54s 840ms/step - loss: 1.3176 - accuracy: 0.6404 - val_loss: 1.5592 - val_accuracy: 0.5847\n\nEpoch 00010: val_accuracy improved from 0.57056 to 0.58468, saving model to ../../working/IIIT.h5\nEpoch 11/200\n64/64 [==============================] - 53s 833ms/step - loss: 1.1445 - accuracy: 0.7075 - val_loss: 1.4675 - val_accuracy: 0.6069\n\nEpoch 00011: val_accuracy improved from 0.58468 to 0.60685, saving model to ../../working/IIIT.h5\nEpoch 12/200\n64/64 [==============================] - 54s 841ms/step - loss: 1.0240 - accuracy: 0.7415 - val_loss: 1.3394 - val_accuracy: 0.6512\n\nEpoch 00012: val_accuracy improved from 0.60685 to 0.65121, saving model to ../../working/IIIT.h5\nEpoch 13/200\n64/64 [==============================] - 54s 840ms/step - loss: 0.9266 - accuracy: 0.7507 - val_loss: 1.2527 - val_accuracy: 0.6492\n\nEpoch 00013: val_accuracy did not improve from 0.65121\nEpoch 14/200\n64/64 [==============================] - 52s 821ms/step - loss: 0.8862 - accuracy: 0.7533 - val_loss: 1.2998 - val_accuracy: 0.6411\n\nEpoch 00014: val_accuracy did not improve from 0.65121\nEpoch 15/200\n64/64 [==============================] - 53s 834ms/step - loss: 0.8554 - accuracy: 0.7821 - val_loss: 1.1262 - val_accuracy: 0.6915\n\nEpoch 00015: val_accuracy improved from 0.65121 to 0.69153, saving model to ../../working/IIIT.h5\nEpoch 16/200\n64/64 [==============================] - 53s 826ms/step - loss: 0.7660 - accuracy: 0.8078 - val_loss: 1.1986 - val_accuracy: 0.6653\n\nEpoch 00016: val_accuracy did not improve from 0.69153\nEpoch 17/200\n64/64 [==============================] - 53s 827ms/step - loss: 0.7108 - accuracy: 0.8202 - val_loss: 1.1227 - val_accuracy: 0.6956\n\nEpoch 00017: val_accuracy improved from 0.69153 to 0.69556, saving model to ../../working/IIIT.h5\nEpoch 18/200\n64/64 [==============================] - 53s 829ms/step - loss: 0.6376 - accuracy: 0.8314 - val_loss: 1.1145 - val_accuracy: 0.6895\n\nEpoch 00018: val_accuracy did not improve from 0.69556\nEpoch 19/200\n64/64 [==============================] - 52s 807ms/step - loss: 0.6358 - accuracy: 0.8338 - val_loss: 1.0070 - val_accuracy: 0.7238\n\nEpoch 00019: val_accuracy improved from 0.69556 to 0.72379, saving model to ../../working/IIIT.h5\nEpoch 20/200\n64/64 [==============================] - 52s 819ms/step - loss: 0.5656 - accuracy: 0.8664 - val_loss: 1.0977 - val_accuracy: 0.6956\n\nEpoch 00020: val_accuracy did not improve from 0.72379\nEpoch 21/200\n64/64 [==============================] - 52s 815ms/step - loss: 0.5704 - accuracy: 0.8547 - val_loss: 0.9089 - val_accuracy: 0.7359\n\nEpoch 00021: val_accuracy improved from 0.72379 to 0.73589, saving model to ../../working/IIIT.h5\nEpoch 22/200\n64/64 [==============================] - 52s 818ms/step - loss: 0.5156 - accuracy: 0.8689 - val_loss: 0.9394 - val_accuracy: 0.7137\n\nEpoch 00022: val_accuracy did not improve from 0.73589\nEpoch 23/200\n64/64 [==============================] - 52s 809ms/step - loss: 0.4950 - accuracy: 0.8871 - val_loss: 0.9826 - val_accuracy: 0.7097\n\nEpoch 00023: val_accuracy did not improve from 0.73589\nEpoch 24/200\n64/64 [==============================] - 53s 827ms/step - loss: 0.4587 - accuracy: 0.8974 - val_loss: 0.9095 - val_accuracy: 0.7278\n\nEpoch 00024: val_accuracy did not improve from 0.73589\nEpoch 25/200\n64/64 [==============================] - 53s 828ms/step - loss: 0.4337 - accuracy: 0.8959 - val_loss: 0.8845 - val_accuracy: 0.7278\n\nEpoch 00025: val_accuracy did not improve from 0.73589\nEpoch 26/200\n64/64 [==============================] - 52s 821ms/step - loss: 0.4048 - accuracy: 0.9117 - val_loss: 0.8871 - val_accuracy: 0.7520\n\nEpoch 00026: val_accuracy improved from 0.73589 to 0.75202, saving model to ../../working/IIIT.h5\nEpoch 27/200\n64/64 [==============================] - 54s 839ms/step - loss: 0.3823 - accuracy: 0.8971 - val_loss: 0.8451 - val_accuracy: 0.7359\n\nEpoch 00027: val_accuracy did not improve from 0.75202\nEpoch 28/200\n64/64 [==============================] - 52s 819ms/step - loss: 0.3625 - accuracy: 0.9171 - val_loss: 0.8703 - val_accuracy: 0.7379\n\nEpoch 00028: val_accuracy did not improve from 0.75202\nEpoch 29/200\n64/64 [==============================] - 53s 830ms/step - loss: 0.3632 - accuracy: 0.9105 - val_loss: 0.9084 - val_accuracy: 0.7117\n\nEpoch 00029: val_accuracy did not improve from 0.75202\nEpoch 30/200\n64/64 [==============================] - 53s 825ms/step - loss: 0.3258 - accuracy: 0.9222 - val_loss: 0.7729 - val_accuracy: 0.7722\n\nEpoch 00030: val_accuracy improved from 0.75202 to 0.77218, saving model to ../../working/IIIT.h5\nEpoch 31/200\n64/64 [==============================] - 53s 824ms/step - loss: 0.3036 - accuracy: 0.9400 - val_loss: 0.8357 - val_accuracy: 0.7480\n\nEpoch 00031: val_accuracy did not improve from 0.77218\nEpoch 32/200\n64/64 [==============================] - 53s 823ms/step - loss: 0.2995 - accuracy: 0.9391 - val_loss: 0.7823 - val_accuracy: 0.7863\n\nEpoch 00032: val_accuracy improved from 0.77218 to 0.78629, saving model to ../../working/IIIT.h5\nEpoch 33/200\n64/64 [==============================] - 52s 814ms/step - loss: 0.3196 - accuracy: 0.9196 - val_loss: 0.8543 - val_accuracy: 0.7319\n\nEpoch 00033: val_accuracy did not improve from 0.78629\nEpoch 34/200\n64/64 [==============================] - 52s 816ms/step - loss: 0.2719 - accuracy: 0.9375 - val_loss: 0.8304 - val_accuracy: 0.7520\n\nEpoch 00034: val_accuracy did not improve from 0.78629\nEpoch 35/200\n64/64 [==============================] - 53s 823ms/step - loss: 0.2905 - accuracy: 0.9242 - val_loss: 0.7619 - val_accuracy: 0.7742\n\nEpoch 00035: val_accuracy did not improve from 0.78629\nEpoch 36/200\n64/64 [==============================] - 52s 816ms/step - loss: 0.2571 - accuracy: 0.9498 - val_loss: 0.8192 - val_accuracy: 0.7440\n\nEpoch 00036: val_accuracy did not improve from 0.78629\nEpoch 37/200\n64/64 [==============================] - 52s 814ms/step - loss: 0.2630 - accuracy: 0.9399 - val_loss: 0.7915 - val_accuracy: 0.7722\n\nEpoch 00037: val_accuracy did not improve from 0.78629\nEpoch 38/200\n64/64 [==============================] - 52s 812ms/step - loss: 0.2612 - accuracy: 0.9339 - val_loss: 0.7775 - val_accuracy: 0.7480\n\nEpoch 00038: val_accuracy did not improve from 0.78629\nEpoch 39/200\n64/64 [==============================] - 52s 817ms/step - loss: 0.2383 - accuracy: 0.9366 - val_loss: 0.7438 - val_accuracy: 0.7661\n\nEpoch 00039: val_accuracy did not improve from 0.78629\nEpoch 40/200\n64/64 [==============================] - 52s 821ms/step - loss: 0.2321 - accuracy: 0.9413 - val_loss: 0.7733 - val_accuracy: 0.7560\n\nEpoch 00040: val_accuracy did not improve from 0.78629\nEpoch 41/200\n64/64 [==============================] - 51s 803ms/step - loss: 0.2262 - accuracy: 0.9424 - val_loss: 0.7958 - val_accuracy: 0.7560\n\nEpoch 00041: val_accuracy did not improve from 0.78629\nEpoch 42/200\n64/64 [==============================] - 52s 820ms/step - loss: 0.1971 - accuracy: 0.9537 - val_loss: 0.7726 - val_accuracy: 0.7560\n\nEpoch 00042: val_accuracy did not improve from 0.78629\nEpoch 43/200\n64/64 [==============================] - 52s 813ms/step - loss: 0.1989 - accuracy: 0.9586 - val_loss: 0.7509 - val_accuracy: 0.7681\n\nEpoch 00043: val_accuracy did not improve from 0.78629\nEpoch 44/200\n64/64 [==============================] - 53s 825ms/step - loss: 0.1797 - accuracy: 0.9568 - val_loss: 0.7304 - val_accuracy: 0.7681\n\nEpoch 00044: val_accuracy did not improve from 0.78629\nEpoch 45/200\n64/64 [==============================] - 52s 818ms/step - loss: 0.1976 - accuracy: 0.9524 - val_loss: 0.7333 - val_accuracy: 0.7944\n\nEpoch 00045: val_accuracy improved from 0.78629 to 0.79435, saving model to ../../working/IIIT.h5\nEpoch 46/200\n64/64 [==============================] - 53s 837ms/step - loss: 0.1896 - accuracy: 0.9616 - val_loss: 0.7707 - val_accuracy: 0.7681\n\nEpoch 00046: val_accuracy did not improve from 0.79435\nEpoch 47/200\n64/64 [==============================] - 54s 840ms/step - loss: 0.1745 - accuracy: 0.9640 - val_loss: 0.7266 - val_accuracy: 0.7681\n\nEpoch 00047: val_accuracy did not improve from 0.79435\nEpoch 48/200\n64/64 [==============================] - 53s 831ms/step - loss: 0.1771 - accuracy: 0.9646 - val_loss: 0.7262 - val_accuracy: 0.7863\n\nEpoch 00048: val_accuracy did not improve from 0.79435\nEpoch 49/200\n64/64 [==============================] - 54s 838ms/step - loss: 0.1635 - accuracy: 0.9671 - val_loss: 0.7508 - val_accuracy: 0.7641\n\nEpoch 00049: val_accuracy did not improve from 0.79435\nEpoch 50/200\n64/64 [==============================] - 53s 837ms/step - loss: 0.1742 - accuracy: 0.9608 - val_loss: 0.6949 - val_accuracy: 0.7863\n\nEpoch 00050: val_accuracy did not improve from 0.79435\nEpoch 51/200\n64/64 [==============================] - 53s 826ms/step - loss: 0.1643 - accuracy: 0.9624 - val_loss: 0.7420 - val_accuracy: 0.7964\n\nEpoch 00051: val_accuracy improved from 0.79435 to 0.79637, saving model to ../../working/IIIT.h5\nEpoch 52/200\n64/64 [==============================] - 54s 843ms/step - loss: 0.1844 - accuracy: 0.9507 - val_loss: 0.7187 - val_accuracy: 0.7823\n\nEpoch 00052: val_accuracy did not improve from 0.79637\nEpoch 53/200\n64/64 [==============================] - 54s 838ms/step - loss: 0.1452 - accuracy: 0.9715 - val_loss: 0.7122 - val_accuracy: 0.7762\n\nEpoch 00053: val_accuracy did not improve from 0.79637\nEpoch 54/200\n64/64 [==============================] - 54s 845ms/step - loss: 0.1333 - accuracy: 0.9752 - val_loss: 0.7233 - val_accuracy: 0.7964\n\nEpoch 00054: val_accuracy did not improve from 0.79637\nEpoch 55/200\n64/64 [==============================] - 54s 845ms/step - loss: 0.1334 - accuracy: 0.9705 - val_loss: 0.7493 - val_accuracy: 0.7742\n\nEpoch 00055: val_accuracy did not improve from 0.79637\nEpoch 56/200\n64/64 [==============================] - 54s 839ms/step - loss: 0.1322 - accuracy: 0.9708 - val_loss: 0.7032 - val_accuracy: 0.7923\n\nEpoch 00056: val_accuracy did not improve from 0.79637\nEpoch 57/200\n64/64 [==============================] - 54s 843ms/step - loss: 0.1187 - accuracy: 0.9826 - val_loss: 0.7045 - val_accuracy: 0.7883\n\nEpoch 00057: val_accuracy did not improve from 0.79637\nEpoch 58/200\n64/64 [==============================] - 54s 847ms/step - loss: 0.1377 - accuracy: 0.9716 - val_loss: 0.6756 - val_accuracy: 0.7984\n\nEpoch 00058: val_accuracy improved from 0.79637 to 0.79839, saving model to ../../working/IIIT.h5\nEpoch 59/200\n64/64 [==============================] - 54s 838ms/step - loss: 0.1209 - accuracy: 0.9760 - val_loss: 0.6894 - val_accuracy: 0.7944\n\nEpoch 00059: val_accuracy did not improve from 0.79839\nEpoch 60/200\n64/64 [==============================] - 54s 844ms/step - loss: 0.1363 - accuracy: 0.9691 - val_loss: 0.7370 - val_accuracy: 0.7883\n\nEpoch 00060: val_accuracy did not improve from 0.79839\nEpoch 61/200\n64/64 [==============================] - 54s 840ms/step - loss: 0.1237 - accuracy: 0.9738 - val_loss: 0.7230 - val_accuracy: 0.7843\n\nEpoch 00061: val_accuracy did not improve from 0.79839\nEpoch 62/200\n64/64 [==============================] - 54s 848ms/step - loss: 0.1238 - accuracy: 0.9765 - val_loss: 0.7068 - val_accuracy: 0.7802\n\nEpoch 00062: val_accuracy did not improve from 0.79839\nEpoch 63/200\n64/64 [==============================] - 54s 852ms/step - loss: 0.1177 - accuracy: 0.9785 - val_loss: 0.6641 - val_accuracy: 0.8145\n\nEpoch 00063: val_accuracy improved from 0.79839 to 0.81452, saving model to ../../working/IIIT.h5\nEpoch 64/200\n64/64 [==============================] - 54s 842ms/step - loss: 0.1122 - accuracy: 0.9796 - val_loss: 0.6869 - val_accuracy: 0.7823\n\nEpoch 00064: val_accuracy did not improve from 0.81452\nEpoch 65/200\n64/64 [==============================] - 54s 848ms/step - loss: 0.1098 - accuracy: 0.9745 - val_loss: 0.6818 - val_accuracy: 0.7964\n\nEpoch 00065: val_accuracy did not improve from 0.81452\nEpoch 66/200\n64/64 [==============================] - 55s 854ms/step - loss: 0.1116 - accuracy: 0.9790 - val_loss: 0.6734 - val_accuracy: 0.8004\n\nEpoch 00066: val_accuracy did not improve from 0.81452\nEpoch 67/200\n64/64 [==============================] - 54s 846ms/step - loss: 0.1012 - accuracy: 0.9815 - val_loss: 0.6786 - val_accuracy: 0.7923\n\nEpoch 00067: val_accuracy did not improve from 0.81452\nEpoch 68/200\n64/64 [==============================] - 54s 851ms/step - loss: 0.1109 - accuracy: 0.9786 - val_loss: 0.6518 - val_accuracy: 0.7843\n\nEpoch 00068: val_accuracy did not improve from 0.81452\nEpoch 69/200\n64/64 [==============================] - 54s 849ms/step - loss: 0.1142 - accuracy: 0.9770 - val_loss: 0.6817 - val_accuracy: 0.7823\n\nEpoch 00069: val_accuracy did not improve from 0.81452\nEpoch 70/200\n64/64 [==============================] - 54s 838ms/step - loss: 0.0962 - accuracy: 0.9810 - val_loss: 0.7154 - val_accuracy: 0.7883\n\nEpoch 00070: val_accuracy did not improve from 0.81452\nEpoch 71/200\n64/64 [==============================] - 54s 844ms/step - loss: 0.1010 - accuracy: 0.9763 - val_loss: 0.6574 - val_accuracy: 0.8105\n\nEpoch 00071: val_accuracy did not improve from 0.81452\nEpoch 72/200\n64/64 [==============================] - 53s 833ms/step - loss: 0.0921 - accuracy: 0.9840 - val_loss: 0.6919 - val_accuracy: 0.7984\n\nEpoch 00072: val_accuracy did not improve from 0.81452\nEpoch 73/200\n64/64 [==============================] - 54s 838ms/step - loss: 0.0926 - accuracy: 0.9851 - val_loss: 0.6587 - val_accuracy: 0.7944\n\nEpoch 00073: val_accuracy did not improve from 0.81452\nEpoch 74/200\n64/64 [==============================] - 53s 835ms/step - loss: 0.0936 - accuracy: 0.9804 - val_loss: 0.6862 - val_accuracy: 0.7984\n\nEpoch 00074: val_accuracy did not improve from 0.81452\nEpoch 75/200\n64/64 [==============================] - 53s 835ms/step - loss: 0.0936 - accuracy: 0.9823 - val_loss: 0.6713 - val_accuracy: 0.7923\n\nEpoch 00075: val_accuracy did not improve from 0.81452\nEpoch 76/200\n64/64 [==============================] - 54s 838ms/step - loss: 0.0828 - accuracy: 0.9827 - val_loss: 0.6926 - val_accuracy: 0.8085\n\nEpoch 00076: val_accuracy did not improve from 0.81452\nEpoch 77/200\n64/64 [==============================] - 53s 837ms/step - loss: 0.0916 - accuracy: 0.9820 - val_loss: 0.6586 - val_accuracy: 0.7984\n\nEpoch 00077: val_accuracy did not improve from 0.81452\nEpoch 78/200\n64/64 [==============================] - 54s 838ms/step - loss: 0.0913 - accuracy: 0.9827 - val_loss: 0.6817 - val_accuracy: 0.7883\n\nEpoch 00078: val_accuracy did not improve from 0.81452\nEpoch 79/200\n64/64 [==============================] - 53s 835ms/step - loss: 0.0766 - accuracy: 0.9858 - val_loss: 0.6905 - val_accuracy: 0.7964\n\nEpoch 00079: val_accuracy did not improve from 0.81452\nEpoch 80/200\n64/64 [==============================] - 53s 829ms/step - loss: 0.0822 - accuracy: 0.9844 - val_loss: 0.6741 - val_accuracy: 0.7984\n\nEpoch 00080: val_accuracy did not improve from 0.81452\nEpoch 81/200\n64/64 [==============================] - 53s 833ms/step - loss: 0.0772 - accuracy: 0.9873 - val_loss: 0.7531 - val_accuracy: 0.7762\n\nEpoch 00081: val_accuracy did not improve from 0.81452\nEpoch 82/200\n64/64 [==============================] - 53s 836ms/step - loss: 0.0821 - accuracy: 0.9827 - val_loss: 0.6533 - val_accuracy: 0.8024\n\nEpoch 00082: val_accuracy did not improve from 0.81452\nEpoch 83/200\n64/64 [==============================] - 53s 833ms/step - loss: 0.0802 - accuracy: 0.9823 - val_loss: 0.6763 - val_accuracy: 0.8085\n\nEpoch 00083: val_accuracy did not improve from 0.81452\nEpoch 84/200\n64/64 [==============================] - 53s 833ms/step - loss: 0.0876 - accuracy: 0.9804 - val_loss: 0.6807 - val_accuracy: 0.8024\n\nEpoch 00084: val_accuracy did not improve from 0.81452\nEpoch 85/200\n64/64 [==============================] - 53s 825ms/step - loss: 0.0872 - accuracy: 0.9776 - val_loss: 0.6713 - val_accuracy: 0.7863\n\nEpoch 00085: val_accuracy did not improve from 0.81452\nEpoch 86/200\n64/64 [==============================] - 52s 817ms/step - loss: 0.0702 - accuracy: 0.9884 - val_loss: 0.6621 - val_accuracy: 0.8004\n\nEpoch 00086: val_accuracy did not improve from 0.81452\nEpoch 87/200\n64/64 [==============================] - 54s 843ms/step - loss: 0.0691 - accuracy: 0.9846 - val_loss: 0.6173 - val_accuracy: 0.8206\n\nEpoch 00087: val_accuracy improved from 0.81452 to 0.82056, saving model to ../../working/IIIT.h5\nEpoch 88/200\n64/64 [==============================] - 54s 841ms/step - loss: 0.0760 - accuracy: 0.9871 - val_loss: 0.6654 - val_accuracy: 0.8185\n\nEpoch 00088: val_accuracy did not improve from 0.82056\nEpoch 89/200\n64/64 [==============================] - 53s 826ms/step - loss: 0.0746 - accuracy: 0.9827 - val_loss: 0.6776 - val_accuracy: 0.7944\n\nEpoch 00089: val_accuracy did not improve from 0.82056\nEpoch 90/200\n64/64 [==============================] - 53s 822ms/step - loss: 0.0708 - accuracy: 0.9890 - val_loss: 0.6804 - val_accuracy: 0.8085\n\nEpoch 00090: val_accuracy did not improve from 0.82056\nEpoch 91/200\n64/64 [==============================] - 52s 806ms/step - loss: 0.0721 - accuracy: 0.9866 - val_loss: 0.6989 - val_accuracy: 0.8004\n\nEpoch 00091: val_accuracy did not improve from 0.82056\nEpoch 92/200\n64/64 [==============================] - 53s 826ms/step - loss: 0.0699 - accuracy: 0.9794 - val_loss: 0.6758 - val_accuracy: 0.8024\n\nEpoch 00092: val_accuracy did not improve from 0.82056\nEpoch 93/200\n64/64 [==============================] - 53s 824ms/step - loss: 0.0653 - accuracy: 0.9912 - val_loss: 0.6776 - val_accuracy: 0.8125\n\nEpoch 00093: val_accuracy did not improve from 0.82056\nEpoch 94/200\n64/64 [==============================] - 52s 821ms/step - loss: 0.0666 - accuracy: 0.9864 - val_loss: 0.7116 - val_accuracy: 0.8024\n\nEpoch 00094: val_accuracy did not improve from 0.82056\nEpoch 95/200\n64/64 [==============================] - 54s 838ms/step - loss: 0.0667 - accuracy: 0.9871 - val_loss: 0.6615 - val_accuracy: 0.8165\n\nEpoch 00095: val_accuracy did not improve from 0.82056\nEpoch 96/200\n64/64 [==============================] - 53s 830ms/step - loss: 0.0549 - accuracy: 0.9902 - val_loss: 0.6875 - val_accuracy: 0.8085\n\nEpoch 00096: val_accuracy did not improve from 0.82056\nEpoch 97/200\n64/64 [==============================] - 53s 828ms/step - loss: 0.0649 - accuracy: 0.9926 - val_loss: 0.6409 - val_accuracy: 0.7984\n\nEpoch 00097: val_accuracy did not improve from 0.82056\nEpoch 98/200\n64/64 [==============================] - 53s 837ms/step - loss: 0.0767 - accuracy: 0.9833 - val_loss: 0.6691 - val_accuracy: 0.8085\n\nEpoch 00098: val_accuracy did not improve from 0.82056\nEpoch 99/200\n64/64 [==============================] - 54s 839ms/step - loss: 0.0580 - accuracy: 0.9877 - val_loss: 0.7005 - val_accuracy: 0.8024\n\nEpoch 00099: val_accuracy did not improve from 0.82056\nEpoch 100/200\n64/64 [==============================] - 53s 834ms/step - loss: 0.0600 - accuracy: 0.9928 - val_loss: 0.6895 - val_accuracy: 0.8105\n\nEpoch 00100: val_accuracy did not improve from 0.82056\nEpoch 101/200\n64/64 [==============================] - 54s 842ms/step - loss: 0.0625 - accuracy: 0.9862 - val_loss: 0.6402 - val_accuracy: 0.8044\n\nEpoch 00101: val_accuracy did not improve from 0.82056\nEpoch 102/200\n64/64 [==============================] - 54s 846ms/step - loss: 0.0587 - accuracy: 0.9863 - val_loss: 0.6672 - val_accuracy: 0.8004\n\nEpoch 00102: val_accuracy did not improve from 0.82056\nEpoch 103/200\n64/64 [==============================] - 53s 836ms/step - loss: 0.0592 - accuracy: 0.9868 - val_loss: 0.7018 - val_accuracy: 0.8004\n\nEpoch 00103: val_accuracy did not improve from 0.82056\nEpoch 104/200\n64/64 [==============================] - 54s 848ms/step - loss: 0.0483 - accuracy: 0.9942 - val_loss: 0.6859 - val_accuracy: 0.7903\n\nEpoch 00104: val_accuracy did not improve from 0.82056\nEpoch 105/200\n64/64 [==============================] - 55s 868ms/step - loss: 0.0500 - accuracy: 0.9906 - val_loss: 0.7116 - val_accuracy: 0.8125\n\nEpoch 00105: val_accuracy did not improve from 0.82056\nEpoch 106/200\n64/64 [==============================] - 55s 868ms/step - loss: 0.0569 - accuracy: 0.9891 - val_loss: 0.6970 - val_accuracy: 0.8004\n\nEpoch 00106: val_accuracy did not improve from 0.82056\nEpoch 107/200\n64/64 [==============================] - 56s 879ms/step - loss: 0.0526 - accuracy: 0.9928 - val_loss: 0.6657 - val_accuracy: 0.8085\n\nEpoch 00107: val_accuracy did not improve from 0.82056\nEpoch 108/200\n64/64 [==============================] - 56s 884ms/step - loss: 0.0578 - accuracy: 0.9863 - val_loss: 0.6723 - val_accuracy: 0.8145\n\nEpoch 00108: val_accuracy did not improve from 0.82056\nEpoch 109/200\n64/64 [==============================] - 56s 880ms/step - loss: 0.0543 - accuracy: 0.9898 - val_loss: 0.6752 - val_accuracy: 0.8105\n\nEpoch 00109: val_accuracy did not improve from 0.82056\nEpoch 110/200\n64/64 [==============================] - 56s 874ms/step - loss: 0.0510 - accuracy: 0.9907 - val_loss: 0.6517 - val_accuracy: 0.8105\n\nEpoch 00110: val_accuracy did not improve from 0.82056\nEpoch 111/200\n64/64 [==============================] - 57s 889ms/step - loss: 0.0539 - accuracy: 0.9883 - val_loss: 0.7037 - val_accuracy: 0.7883\n\nEpoch 00111: val_accuracy did not improve from 0.82056\nEpoch 112/200\n64/64 [==============================] - 56s 880ms/step - loss: 0.0514 - accuracy: 0.9893 - val_loss: 0.6455 - val_accuracy: 0.8185\n\nEpoch 00112: val_accuracy did not improve from 0.82056\nEpoch 113/200\n64/64 [==============================] - 56s 872ms/step - loss: 0.0607 - accuracy: 0.9904 - val_loss: 0.6501 - val_accuracy: 0.8165\n\nEpoch 00113: val_accuracy did not improve from 0.82056\nEpoch 114/200\n64/64 [==============================] - 56s 882ms/step - loss: 0.0546 - accuracy: 0.9893 - val_loss: 0.6830 - val_accuracy: 0.8065\n\nEpoch 00114: val_accuracy did not improve from 0.82056\nEpoch 115/200\n64/64 [==============================] - 56s 876ms/step - loss: 0.0523 - accuracy: 0.9929 - val_loss: 0.6783 - val_accuracy: 0.8165\n\nEpoch 00115: val_accuracy did not improve from 0.82056\nEpoch 116/200\n64/64 [==============================] - 56s 872ms/step - loss: 0.0541 - accuracy: 0.9874 - val_loss: 0.6844 - val_accuracy: 0.8085\n\nEpoch 00116: val_accuracy did not improve from 0.82056\nEpoch 117/200\n64/64 [==============================] - 56s 873ms/step - loss: 0.0480 - accuracy: 0.9943 - val_loss: 0.6570 - val_accuracy: 0.8206\n\nEpoch 00117: val_accuracy did not improve from 0.82056\nEpoch 118/200\n64/64 [==============================] - 56s 882ms/step - loss: 0.0453 - accuracy: 0.9939 - val_loss: 0.7091 - val_accuracy: 0.8105\n\nEpoch 00118: val_accuracy did not improve from 0.82056\nEpoch 119/200\n64/64 [==============================] - 56s 884ms/step - loss: 0.0465 - accuracy: 0.9932 - val_loss: 0.6544 - val_accuracy: 0.8044\n\nEpoch 00119: val_accuracy did not improve from 0.82056\nEpoch 120/200\n64/64 [==============================] - 56s 874ms/step - loss: 0.0532 - accuracy: 0.9891 - val_loss: 0.6908 - val_accuracy: 0.8065\n\nEpoch 00120: val_accuracy did not improve from 0.82056\nEpoch 121/200\n64/64 [==============================] - 56s 880ms/step - loss: 0.0399 - accuracy: 0.9946 - val_loss: 0.6982 - val_accuracy: 0.7944\n\nEpoch 00121: val_accuracy did not improve from 0.82056\nEpoch 122/200\n64/64 [==============================] - 56s 879ms/step - loss: 0.0362 - accuracy: 0.9958 - val_loss: 0.6717 - val_accuracy: 0.8105\n\nEpoch 00122: val_accuracy did not improve from 0.82056\nEpoch 123/200\n64/64 [==============================] - 56s 875ms/step - loss: 0.0492 - accuracy: 0.9878 - val_loss: 0.6619 - val_accuracy: 0.8105\n\nEpoch 00123: val_accuracy did not improve from 0.82056\nEpoch 124/200\n64/64 [==============================] - 56s 877ms/step - loss: 0.0514 - accuracy: 0.9884 - val_loss: 0.6400 - val_accuracy: 0.8206\n\nEpoch 00124: val_accuracy did not improve from 0.82056\nEpoch 125/200\n64/64 [==============================] - 56s 876ms/step - loss: 0.0458 - accuracy: 0.9902 - val_loss: 0.6602 - val_accuracy: 0.8145\n\nEpoch 00125: val_accuracy did not improve from 0.82056\nEpoch 126/200\n64/64 [==============================] - 56s 868ms/step - loss: 0.0400 - accuracy: 0.9948 - val_loss: 0.6590 - val_accuracy: 0.8125\n\nEpoch 00126: val_accuracy did not improve from 0.82056\nEpoch 127/200\n64/64 [==============================] - 56s 869ms/step - loss: 0.0457 - accuracy: 0.9890 - val_loss: 0.6671 - val_accuracy: 0.8145\n\nEpoch 00127: val_accuracy did not improve from 0.82056\nEpoch 128/200\n64/64 [==============================] - 56s 877ms/step - loss: 0.0408 - accuracy: 0.9955 - val_loss: 0.6547 - val_accuracy: 0.8145\n\nEpoch 00128: val_accuracy did not improve from 0.82056\nEpoch 129/200\n64/64 [==============================] - 56s 877ms/step - loss: 0.0438 - accuracy: 0.9932 - val_loss: 0.6594 - val_accuracy: 0.8105\n\nEpoch 00129: val_accuracy did not improve from 0.82056\nEpoch 130/200\n64/64 [==============================] - 56s 870ms/step - loss: 0.0393 - accuracy: 0.9937 - val_loss: 0.7157 - val_accuracy: 0.8024\n\nEpoch 00130: val_accuracy did not improve from 0.82056\nEpoch 131/200\n64/64 [==============================] - 56s 879ms/step - loss: 0.0355 - accuracy: 0.9965 - val_loss: 0.7019 - val_accuracy: 0.8004\n\nEpoch 00131: val_accuracy did not improve from 0.82056\nEpoch 132/200\n64/64 [==============================] - 56s 876ms/step - loss: 0.0350 - accuracy: 0.9938 - val_loss: 0.6924 - val_accuracy: 0.8065\n\nEpoch 00132: val_accuracy did not improve from 0.82056\nEpoch 133/200\n64/64 [==============================] - 56s 876ms/step - loss: 0.0476 - accuracy: 0.9916 - val_loss: 0.6959 - val_accuracy: 0.8024\n\nEpoch 00133: val_accuracy did not improve from 0.82056\nEpoch 134/200\n64/64 [==============================] - 56s 871ms/step - loss: 0.0369 - accuracy: 0.9968 - val_loss: 0.6876 - val_accuracy: 0.8125\n\nEpoch 00134: val_accuracy did not improve from 0.82056\nEpoch 135/200\n64/64 [==============================] - 56s 873ms/step - loss: 0.0320 - accuracy: 0.9964 - val_loss: 0.7018 - val_accuracy: 0.8044\n\nEpoch 00135: val_accuracy did not improve from 0.82056\nEpoch 136/200\n64/64 [==============================] - 56s 874ms/step - loss: 0.0347 - accuracy: 0.9944 - val_loss: 0.7014 - val_accuracy: 0.8065\n\nEpoch 00136: val_accuracy did not improve from 0.82056\nEpoch 137/200\n64/64 [==============================] - 56s 869ms/step - loss: 0.0368 - accuracy: 0.9932 - val_loss: 0.6951 - val_accuracy: 0.8105\n\nEpoch 00137: val_accuracy did not improve from 0.82056\nEpoch 138/200\n64/64 [==============================] - 56s 882ms/step - loss: 0.0408 - accuracy: 0.9939 - val_loss: 0.7095 - val_accuracy: 0.8065\n\nEpoch 00138: val_accuracy did not improve from 0.82056\nEpoch 139/200\n64/64 [==============================] - 56s 879ms/step - loss: 0.0442 - accuracy: 0.9888 - val_loss: 0.6896 - val_accuracy: 0.8125\n\nEpoch 00139: val_accuracy did not improve from 0.82056\nEpoch 140/200\n64/64 [==============================] - 56s 869ms/step - loss: 0.0375 - accuracy: 0.9943 - val_loss: 0.6787 - val_accuracy: 0.8044\n\nEpoch 00140: val_accuracy did not improve from 0.82056\nEpoch 141/200\n64/64 [==============================] - 56s 875ms/step - loss: 0.0299 - accuracy: 0.9975 - val_loss: 0.6797 - val_accuracy: 0.8125\n\nEpoch 00141: val_accuracy did not improve from 0.82056\nEpoch 142/200\n64/64 [==============================] - 56s 881ms/step - loss: 0.0362 - accuracy: 0.9935 - val_loss: 0.6587 - val_accuracy: 0.8085\n\nEpoch 00142: val_accuracy did not improve from 0.82056\nEpoch 143/200\n64/64 [==============================] - 55s 868ms/step - loss: 0.0374 - accuracy: 0.9906 - val_loss: 0.6718 - val_accuracy: 0.8286\n\nEpoch 00143: val_accuracy improved from 0.82056 to 0.82863, saving model to ../../working/IIIT.h5\nEpoch 144/200\n64/64 [==============================] - 56s 877ms/step - loss: 0.0387 - accuracy: 0.9925 - val_loss: 0.6434 - val_accuracy: 0.8226\n\nEpoch 00144: val_accuracy did not improve from 0.82863\nEpoch 145/200\n64/64 [==============================] - 56s 877ms/step - loss: 0.0362 - accuracy: 0.9934 - val_loss: 0.6637 - val_accuracy: 0.8185\n\nEpoch 00145: val_accuracy did not improve from 0.82863\nEpoch 146/200\n64/64 [==============================] - 56s 877ms/step - loss: 0.0303 - accuracy: 0.9954 - val_loss: 0.6971 - val_accuracy: 0.8145\n\nEpoch 00146: val_accuracy did not improve from 0.82863\nEpoch 147/200\n64/64 [==============================] - 56s 871ms/step - loss: 0.0317 - accuracy: 0.9961 - val_loss: 0.7215 - val_accuracy: 0.8145\n\nEpoch 00147: val_accuracy did not improve from 0.82863\nEpoch 148/200\n64/64 [==============================] - 56s 881ms/step - loss: 0.0331 - accuracy: 0.9950 - val_loss: 0.7085 - val_accuracy: 0.7944\n\nEpoch 00148: val_accuracy did not improve from 0.82863\nEpoch 149/200\n64/64 [==============================] - 56s 875ms/step - loss: 0.0293 - accuracy: 0.9951 - val_loss: 0.7050 - val_accuracy: 0.8125\n\nEpoch 00149: val_accuracy did not improve from 0.82863\nEpoch 150/200\n64/64 [==============================] - 56s 869ms/step - loss: 0.0365 - accuracy: 0.9928 - val_loss: 0.6896 - val_accuracy: 0.8145\n\nEpoch 00150: val_accuracy did not improve from 0.82863\nEpoch 151/200\n64/64 [==============================] - 56s 881ms/step - loss: 0.0359 - accuracy: 0.9912 - val_loss: 0.7048 - val_accuracy: 0.8185\n\nEpoch 00151: val_accuracy did not improve from 0.82863\nEpoch 152/200\n64/64 [==============================] - 56s 877ms/step - loss: 0.0253 - accuracy: 0.9972 - val_loss: 0.6677 - val_accuracy: 0.8367\n\nEpoch 00152: val_accuracy improved from 0.82863 to 0.83669, saving model to ../../working/IIIT.h5\nEpoch 153/200\n64/64 [==============================] - 55s 867ms/step - loss: 0.0370 - accuracy: 0.9924 - val_loss: 0.6916 - val_accuracy: 0.8085\n\nEpoch 00153: val_accuracy did not improve from 0.83669\nEpoch 154/200\n64/64 [==============================] - 56s 876ms/step - loss: 0.0396 - accuracy: 0.9922 - val_loss: 0.6677 - val_accuracy: 0.8246\n\nEpoch 00154: val_accuracy did not improve from 0.83669\nEpoch 155/200\n64/64 [==============================] - 56s 876ms/step - loss: 0.0296 - accuracy: 0.9971 - val_loss: 0.6791 - val_accuracy: 0.8105\n\nEpoch 00155: val_accuracy did not improve from 0.83669\nEpoch 156/200\n64/64 [==============================] - 56s 874ms/step - loss: 0.0366 - accuracy: 0.9948 - val_loss: 0.7003 - val_accuracy: 0.8226\n\nEpoch 00156: val_accuracy did not improve from 0.83669\nEpoch 157/200\n64/64 [==============================] - 55s 868ms/step - loss: 0.0273 - accuracy: 0.9980 - val_loss: 0.6828 - val_accuracy: 0.8206\n\nEpoch 00157: val_accuracy did not improve from 0.83669\nEpoch 158/200\n64/64 [==============================] - 56s 876ms/step - loss: 0.0293 - accuracy: 0.9944 - val_loss: 0.6745 - val_accuracy: 0.8105\n\nEpoch 00158: val_accuracy did not improve from 0.83669\nEpoch 159/200\n64/64 [==============================] - 56s 874ms/step - loss: 0.0358 - accuracy: 0.9944 - val_loss: 0.6858 - val_accuracy: 0.8105\n\nEpoch 00159: val_accuracy did not improve from 0.83669\nEpoch 160/200\n64/64 [==============================] - 56s 870ms/step - loss: 0.0376 - accuracy: 0.9923 - val_loss: 0.6338 - val_accuracy: 0.8266\n\nEpoch 00160: val_accuracy did not improve from 0.83669\nEpoch 161/200\n64/64 [==============================] - 56s 873ms/step - loss: 0.0261 - accuracy: 0.9988 - val_loss: 0.6963 - val_accuracy: 0.8165\n\nEpoch 00161: val_accuracy did not improve from 0.83669\nEpoch 162/200\n64/64 [==============================] - 56s 875ms/step - loss: 0.0319 - accuracy: 0.9959 - val_loss: 0.6787 - val_accuracy: 0.8286\n\nEpoch 00162: val_accuracy did not improve from 0.83669\nEpoch 163/200\n64/64 [==============================] - 56s 867ms/step - loss: 0.0272 - accuracy: 0.9968 - val_loss: 0.6938 - val_accuracy: 0.8246\n\nEpoch 00163: val_accuracy did not improve from 0.83669\nEpoch 164/200\n64/64 [==============================] - 56s 876ms/step - loss: 0.0305 - accuracy: 0.9961 - val_loss: 0.6841 - val_accuracy: 0.8165\n\nEpoch 00164: val_accuracy did not improve from 0.83669\nEpoch 165/200\n64/64 [==============================] - 56s 874ms/step - loss: 0.0292 - accuracy: 0.9959 - val_loss: 0.7163 - val_accuracy: 0.8065\n\nEpoch 00165: val_accuracy did not improve from 0.83669\nEpoch 166/200\n64/64 [==============================] - 55s 869ms/step - loss: 0.0299 - accuracy: 0.9969 - val_loss: 0.7043 - val_accuracy: 0.8065\n\nEpoch 00166: val_accuracy did not improve from 0.83669\nEpoch 167/200\n64/64 [==============================] - 56s 877ms/step - loss: 0.0256 - accuracy: 0.9967 - val_loss: 0.6980 - val_accuracy: 0.8226\n\nEpoch 00167: val_accuracy did not improve from 0.83669\nEpoch 168/200\n64/64 [==============================] - 56s 873ms/step - loss: 0.0259 - accuracy: 0.9948 - val_loss: 0.7027 - val_accuracy: 0.8024\n\nEpoch 00168: val_accuracy did not improve from 0.83669\nEpoch 169/200\n64/64 [==============================] - 56s 874ms/step - loss: 0.0251 - accuracy: 0.9967 - val_loss: 0.6739 - val_accuracy: 0.8105\n\nEpoch 00169: val_accuracy did not improve from 0.83669\nEpoch 170/200\n64/64 [==============================] - 56s 870ms/step - loss: 0.0252 - accuracy: 0.9971 - val_loss: 0.7148 - val_accuracy: 0.8065\n\nEpoch 00170: val_accuracy did not improve from 0.83669\nEpoch 171/200\n64/64 [==============================] - 56s 878ms/step - loss: 0.0263 - accuracy: 0.9961 - val_loss: 0.6853 - val_accuracy: 0.8165\n\nEpoch 00171: val_accuracy did not improve from 0.83669\nEpoch 172/200\n64/64 [==============================] - 56s 876ms/step - loss: 0.0241 - accuracy: 0.9986 - val_loss: 0.6705 - val_accuracy: 0.8246\n\nEpoch 00172: val_accuracy did not improve from 0.83669\nEpoch 173/200\n64/64 [==============================] - 56s 873ms/step - loss: 0.0302 - accuracy: 0.9946 - val_loss: 0.6962 - val_accuracy: 0.8105\n\nEpoch 00173: val_accuracy did not improve from 0.83669\nEpoch 174/200\n64/64 [==============================] - 56s 876ms/step - loss: 0.0315 - accuracy: 0.9951 - val_loss: 0.7243 - val_accuracy: 0.8165\n\nEpoch 00174: val_accuracy did not improve from 0.83669\nEpoch 175/200\n64/64 [==============================] - 56s 876ms/step - loss: 0.0260 - accuracy: 0.9987 - val_loss: 0.6857 - val_accuracy: 0.8044\n\nEpoch 00175: val_accuracy did not improve from 0.83669\nEpoch 176/200\n64/64 [==============================] - 56s 870ms/step - loss: 0.0260 - accuracy: 0.9943 - val_loss: 0.6727 - val_accuracy: 0.8125\n\nEpoch 00176: val_accuracy did not improve from 0.83669\nEpoch 177/200\n64/64 [==============================] - 56s 879ms/step - loss: 0.0276 - accuracy: 0.9969 - val_loss: 0.6651 - val_accuracy: 0.8125\n\nEpoch 00177: val_accuracy did not improve from 0.83669\nEpoch 178/200\n64/64 [==============================] - 56s 876ms/step - loss: 0.0205 - accuracy: 0.9986 - val_loss: 0.7014 - val_accuracy: 0.8125\n\nEpoch 00178: val_accuracy did not improve from 0.83669\nEpoch 179/200\n64/64 [==============================] - 56s 880ms/step - loss: 0.0340 - accuracy: 0.9924 - val_loss: 0.6735 - val_accuracy: 0.8226\n\nEpoch 00179: val_accuracy did not improve from 0.83669\nEpoch 180/200\n64/64 [==============================] - 56s 871ms/step - loss: 0.0239 - accuracy: 0.9971 - val_loss: 0.6348 - val_accuracy: 0.8286\n\nEpoch 00180: val_accuracy did not improve from 0.83669\nEpoch 181/200\n64/64 [==============================] - 56s 884ms/step - loss: 0.0286 - accuracy: 0.9931 - val_loss: 0.6792 - val_accuracy: 0.8165\n\nEpoch 00181: val_accuracy did not improve from 0.83669\nEpoch 182/200\n64/64 [==============================] - 56s 880ms/step - loss: 0.0300 - accuracy: 0.9937 - val_loss: 0.7322 - val_accuracy: 0.8105\n\nEpoch 00182: val_accuracy did not improve from 0.83669\nEpoch 183/200\n64/64 [==============================] - 56s 876ms/step - loss: 0.0262 - accuracy: 0.9940 - val_loss: 0.6886 - val_accuracy: 0.8347\n\nEpoch 00183: val_accuracy did not improve from 0.83669\nEpoch 184/200\n64/64 [==============================] - 56s 884ms/step - loss: 0.0253 - accuracy: 0.9949 - val_loss: 0.7156 - val_accuracy: 0.8125\n\nEpoch 00184: val_accuracy did not improve from 0.83669\nEpoch 185/200\n64/64 [==============================] - 57s 885ms/step - loss: 0.0209 - accuracy: 0.9980 - val_loss: 0.7198 - val_accuracy: 0.8004\n\nEpoch 00185: val_accuracy did not improve from 0.83669\nEpoch 186/200\n64/64 [==============================] - 56s 881ms/step - loss: 0.0261 - accuracy: 0.9954 - val_loss: 0.7045 - val_accuracy: 0.8185\n\nEpoch 00186: val_accuracy did not improve from 0.83669\nEpoch 187/200\n64/64 [==============================] - 56s 871ms/step - loss: 0.0246 - accuracy: 0.9952 - val_loss: 0.7220 - val_accuracy: 0.8165\n\nEpoch 00187: val_accuracy did not improve from 0.83669\nEpoch 188/200\n64/64 [==============================] - 56s 877ms/step - loss: 0.0266 - accuracy: 0.9956 - val_loss: 0.6959 - val_accuracy: 0.8185\n\nEpoch 00188: val_accuracy did not improve from 0.83669\nEpoch 189/200\n64/64 [==============================] - 56s 877ms/step - loss: 0.0224 - accuracy: 0.9957 - val_loss: 0.6757 - val_accuracy: 0.8185\n\nEpoch 00189: val_accuracy did not improve from 0.83669\nEpoch 190/200\n64/64 [==============================] - 55s 867ms/step - loss: 0.0245 - accuracy: 0.9987 - val_loss: 0.7112 - val_accuracy: 0.8125\n\nEpoch 00190: val_accuracy did not improve from 0.83669\nEpoch 191/200\n64/64 [==============================] - 56s 870ms/step - loss: 0.0190 - accuracy: 0.9975 - val_loss: 0.7153 - val_accuracy: 0.8206\n\nEpoch 00191: val_accuracy did not improve from 0.83669\nEpoch 192/200\n64/64 [==============================] - 56s 879ms/step - loss: 0.0212 - accuracy: 0.9975 - val_loss: 0.6800 - val_accuracy: 0.8226\n\nEpoch 00192: val_accuracy did not improve from 0.83669\nEpoch 193/200\n64/64 [==============================] - 56s 874ms/step - loss: 0.0206 - accuracy: 0.9986 - val_loss: 0.6697 - val_accuracy: 0.8125\n\nEpoch 00193: val_accuracy did not improve from 0.83669\nEpoch 194/200\n64/64 [==============================] - 56s 872ms/step - loss: 0.0176 - accuracy: 0.9978 - val_loss: 0.6818 - val_accuracy: 0.8246\n\nEpoch 00194: val_accuracy did not improve from 0.83669\nEpoch 195/200\n64/64 [==============================] - 56s 875ms/step - loss: 0.0189 - accuracy: 0.9974 - val_loss: 0.7134 - val_accuracy: 0.8085\n\nEpoch 00195: val_accuracy did not improve from 0.83669\nEpoch 196/200\n64/64 [==============================] - 56s 878ms/step - loss: 0.0279 - accuracy: 0.9961 - val_loss: 0.6886 - val_accuracy: 0.8185\n\nEpoch 00196: val_accuracy did not improve from 0.83669\nEpoch 197/200\n64/64 [==============================] - 56s 878ms/step - loss: 0.0183 - accuracy: 0.9976 - val_loss: 0.6447 - val_accuracy: 0.8347\n\nEpoch 00197: val_accuracy did not improve from 0.83669\nEpoch 198/200\n64/64 [==============================] - 56s 871ms/step - loss: 0.0228 - accuracy: 0.9972 - val_loss: 0.6629 - val_accuracy: 0.8165\n\nEpoch 00198: val_accuracy did not improve from 0.83669\nEpoch 199/200\n64/64 [==============================] - 56s 874ms/step - loss: 0.0241 - accuracy: 0.9955 - val_loss: 0.7038 - val_accuracy: 0.8145\n\nEpoch 00199: val_accuracy did not improve from 0.83669\nEpoch 200/200\n64/64 [==============================] - 56s 876ms/step - loss: 0.0233 - accuracy: 0.9951 - val_loss: 0.7100 - val_accuracy: 0.8246\n\nEpoch 00200: val_accuracy did not improve from 0.83669\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f1ccc4c8590>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Max accuracy obtained on val data is 83.669 %","metadata":{}},{"cell_type":"markdown","source":"# Model with similar architecture but with different input size","metadata":{}},{"cell_type":"code","source":"model=Sequential()\nmodel.add(Conv2D(64, (5, 5), padding=\"same\",input_shape=(28,28,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(256, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(250))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\nmodel.add(Dense(62))\nmodel.add(Activation(\"softmax\"))","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Compiling with same values of learning rate, decay and momentum","metadata":{}},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer= lr_schedule)","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"code","source":"model.fit(train_it,steps_per_epoch=int(1984/62),epochs=200,validation_data=test_it,validation_steps=int(496/62),callbacks=callbacks_list)\n","metadata":{"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/200\n32/32 [==============================] - 40s 1s/step - loss: 4.8360 - accuracy: 0.0222 - val_loss: 4.3908 - val_accuracy: 0.0323\n\nEpoch 00001: val_accuracy improved from 0.01411 to 0.03226, saving model to ../../working/IIIT.h5\nEpoch 2/200\n32/32 [==============================] - 40s 1s/step - loss: 4.6259 - accuracy: 0.0307 - val_loss: 4.3036 - val_accuracy: 0.0262\n\nEpoch 00002: val_accuracy did not improve from 0.03226\nEpoch 3/200\n32/32 [==============================] - 40s 1s/step - loss: 4.4427 - accuracy: 0.0358 - val_loss: 4.1228 - val_accuracy: 0.0524\n\nEpoch 00003: val_accuracy improved from 0.03226 to 0.05242, saving model to ../../working/IIIT.h5\nEpoch 4/200\n32/32 [==============================] - 39s 1s/step - loss: 4.2118 - accuracy: 0.0494 - val_loss: 3.8616 - val_accuracy: 0.0726\n\nEpoch 00004: val_accuracy improved from 0.05242 to 0.07258, saving model to ../../working/IIIT.h5\nEpoch 5/200\n32/32 [==============================] - 40s 1s/step - loss: 4.0156 - accuracy: 0.0716 - val_loss: 3.7397 - val_accuracy: 0.0827\n\nEpoch 00005: val_accuracy improved from 0.07258 to 0.08266, saving model to ../../working/IIIT.h5\nEpoch 6/200\n32/32 [==============================] - 39s 1s/step - loss: 3.8926 - accuracy: 0.0781 - val_loss: 3.5524 - val_accuracy: 0.1210\n\nEpoch 00006: val_accuracy improved from 0.08266 to 0.12097, saving model to ../../working/IIIT.h5\nEpoch 7/200\n32/32 [==============================] - 39s 1s/step - loss: 3.7101 - accuracy: 0.1114 - val_loss: 3.5064 - val_accuracy: 0.0968\n\nEpoch 00007: val_accuracy did not improve from 0.12097\nEpoch 8/200\n32/32 [==============================] - 40s 1s/step - loss: 3.5765 - accuracy: 0.1230 - val_loss: 3.3486 - val_accuracy: 0.1593\n\nEpoch 00008: val_accuracy improved from 0.12097 to 0.15927, saving model to ../../working/IIIT.h5\nEpoch 9/200\n32/32 [==============================] - 40s 1s/step - loss: 3.4081 - accuracy: 0.1431 - val_loss: 3.0791 - val_accuracy: 0.2016\n\nEpoch 00009: val_accuracy improved from 0.15927 to 0.20161, saving model to ../../working/IIIT.h5\nEpoch 10/200\n32/32 [==============================] - 39s 1s/step - loss: 3.2793 - accuracy: 0.1709 - val_loss: 3.0500 - val_accuracy: 0.2077\n\nEpoch 00010: val_accuracy improved from 0.20161 to 0.20766, saving model to ../../working/IIIT.h5\nEpoch 11/200\n32/32 [==============================] - 39s 1s/step - loss: 3.1078 - accuracy: 0.2056 - val_loss: 2.9149 - val_accuracy: 0.2460\n\nEpoch 00011: val_accuracy improved from 0.20766 to 0.24597, saving model to ../../working/IIIT.h5\nEpoch 12/200\n32/32 [==============================] - 40s 1s/step - loss: 2.9593 - accuracy: 0.2308 - val_loss: 2.6925 - val_accuracy: 0.3185\n\nEpoch 00012: val_accuracy improved from 0.24597 to 0.31855, saving model to ../../working/IIIT.h5\nEpoch 13/200\n32/32 [==============================] - 40s 1s/step - loss: 2.8007 - accuracy: 0.2707 - val_loss: 2.6210 - val_accuracy: 0.3165\n\nEpoch 00013: val_accuracy did not improve from 0.31855\nEpoch 14/200\n32/32 [==============================] - 40s 1s/step - loss: 2.6591 - accuracy: 0.2964 - val_loss: 2.6165 - val_accuracy: 0.3407\n\nEpoch 00014: val_accuracy improved from 0.31855 to 0.34073, saving model to ../../working/IIIT.h5\nEpoch 15/200\n32/32 [==============================] - 40s 1s/step - loss: 2.5054 - accuracy: 0.3206 - val_loss: 2.3934 - val_accuracy: 0.3710\n\nEpoch 00015: val_accuracy improved from 0.34073 to 0.37097, saving model to ../../working/IIIT.h5\nEpoch 16/200\n32/32 [==============================] - 40s 1s/step - loss: 2.4298 - accuracy: 0.3483 - val_loss: 2.3237 - val_accuracy: 0.4012\n\nEpoch 00016: val_accuracy improved from 0.37097 to 0.40121, saving model to ../../working/IIIT.h5\nEpoch 17/200\n32/32 [==============================] - 39s 1s/step - loss: 2.2819 - accuracy: 0.3836 - val_loss: 2.2741 - val_accuracy: 0.3790\n\nEpoch 00017: val_accuracy did not improve from 0.40121\nEpoch 18/200\n32/32 [==============================] - 40s 1s/step - loss: 2.1358 - accuracy: 0.4163 - val_loss: 2.1738 - val_accuracy: 0.4214\n\nEpoch 00018: val_accuracy improved from 0.40121 to 0.42137, saving model to ../../working/IIIT.h5\nEpoch 19/200\n32/32 [==============================] - 39s 1s/step - loss: 2.0136 - accuracy: 0.4511 - val_loss: 1.9701 - val_accuracy: 0.4758\n\nEpoch 00019: val_accuracy improved from 0.42137 to 0.47581, saving model to ../../working/IIIT.h5\nEpoch 20/200\n32/32 [==============================] - 39s 1s/step - loss: 1.9415 - accuracy: 0.4556 - val_loss: 1.9376 - val_accuracy: 0.4879\n\nEpoch 00020: val_accuracy improved from 0.47581 to 0.48790, saving model to ../../working/IIIT.h5\nEpoch 21/200\n32/32 [==============================] - 40s 1s/step - loss: 1.8502 - accuracy: 0.4829 - val_loss: 1.8157 - val_accuracy: 0.5060\n\nEpoch 00021: val_accuracy improved from 0.48790 to 0.50605, saving model to ../../working/IIIT.h5\nEpoch 22/200\n32/32 [==============================] - 39s 1s/step - loss: 1.7636 - accuracy: 0.5005 - val_loss: 1.7213 - val_accuracy: 0.5302\n\nEpoch 00022: val_accuracy improved from 0.50605 to 0.53024, saving model to ../../working/IIIT.h5\nEpoch 23/200\n32/32 [==============================] - 39s 1s/step - loss: 1.6584 - accuracy: 0.5489 - val_loss: 1.7598 - val_accuracy: 0.5020\n\nEpoch 00023: val_accuracy did not improve from 0.53024\nEpoch 24/200\n32/32 [==============================] - 39s 1s/step - loss: 1.6149 - accuracy: 0.5539 - val_loss: 1.6954 - val_accuracy: 0.5645\n\nEpoch 00024: val_accuracy improved from 0.53024 to 0.56452, saving model to ../../working/IIIT.h5\nEpoch 25/200\n32/32 [==============================] - 40s 1s/step - loss: 1.5478 - accuracy: 0.5660 - val_loss: 1.5545 - val_accuracy: 0.5544\n\nEpoch 00025: val_accuracy did not improve from 0.56452\nEpoch 26/200\n32/32 [==============================] - 40s 1s/step - loss: 1.5072 - accuracy: 0.5721 - val_loss: 1.7033 - val_accuracy: 0.5383\n\nEpoch 00026: val_accuracy did not improve from 0.56452\nEpoch 27/200\n32/32 [==============================] - 40s 1s/step - loss: 1.4263 - accuracy: 0.5963 - val_loss: 1.5464 - val_accuracy: 0.5746\n\nEpoch 00027: val_accuracy improved from 0.56452 to 0.57460, saving model to ../../working/IIIT.h5\nEpoch 28/200\n32/32 [==============================] - 40s 1s/step - loss: 1.4001 - accuracy: 0.5872 - val_loss: 1.6256 - val_accuracy: 0.5444\n\nEpoch 00028: val_accuracy did not improve from 0.57460\nEpoch 29/200\n32/32 [==============================] - 40s 1s/step - loss: 1.3213 - accuracy: 0.6235 - val_loss: 1.4835 - val_accuracy: 0.6109\n\nEpoch 00029: val_accuracy improved from 0.57460 to 0.61089, saving model to ../../working/IIIT.h5\nEpoch 30/200\n32/32 [==============================] - 40s 1s/step - loss: 1.2681 - accuracy: 0.6356 - val_loss: 1.4586 - val_accuracy: 0.6210\n\nEpoch 00030: val_accuracy improved from 0.61089 to 0.62097, saving model to ../../working/IIIT.h5\nEpoch 31/200\n32/32 [==============================] - 40s 1s/step - loss: 1.2311 - accuracy: 0.6537 - val_loss: 1.3663 - val_accuracy: 0.6310\n\nEpoch 00031: val_accuracy improved from 0.62097 to 0.63105, saving model to ../../working/IIIT.h5\nEpoch 32/200\n32/32 [==============================] - 39s 1s/step - loss: 1.1770 - accuracy: 0.6663 - val_loss: 1.3153 - val_accuracy: 0.6250\n\nEpoch 00032: val_accuracy did not improve from 0.63105\nEpoch 33/200\n32/32 [==============================] - 39s 1s/step - loss: 1.1848 - accuracy: 0.6668 - val_loss: 1.5489 - val_accuracy: 0.5806\n\nEpoch 00033: val_accuracy did not improve from 0.63105\nEpoch 34/200\n32/32 [==============================] - 40s 1s/step - loss: 1.1225 - accuracy: 0.6840 - val_loss: 1.3518 - val_accuracy: 0.6310\n\nEpoch 00034: val_accuracy did not improve from 0.63105\nEpoch 35/200\n32/32 [==============================] - 39s 1s/step - loss: 1.0819 - accuracy: 0.6794 - val_loss: 1.2563 - val_accuracy: 0.6452\n\nEpoch 00035: val_accuracy improved from 0.63105 to 0.64516, saving model to ../../working/IIIT.h5\nEpoch 36/200\n32/32 [==============================] - 39s 1s/step - loss: 1.0333 - accuracy: 0.7036 - val_loss: 1.2372 - val_accuracy: 0.6452\n\nEpoch 00036: val_accuracy did not improve from 0.64516\nEpoch 37/200\n32/32 [==============================] - 38s 1s/step - loss: 1.0039 - accuracy: 0.7077 - val_loss: 1.2696 - val_accuracy: 0.6391\n\nEpoch 00037: val_accuracy did not improve from 0.64516\nEpoch 38/200\n32/32 [==============================] - 38s 1s/step - loss: 0.9613 - accuracy: 0.7208 - val_loss: 1.2339 - val_accuracy: 0.6452\n\nEpoch 00038: val_accuracy did not improve from 0.64516\nEpoch 39/200\n32/32 [==============================] - 38s 1s/step - loss: 0.9928 - accuracy: 0.7177 - val_loss: 1.2577 - val_accuracy: 0.6431\n\nEpoch 00039: val_accuracy did not improve from 0.64516\nEpoch 40/200\n32/32 [==============================] - 38s 1s/step - loss: 0.9352 - accuracy: 0.7238 - val_loss: 1.2087 - val_accuracy: 0.6673\n\nEpoch 00040: val_accuracy improved from 0.64516 to 0.66734, saving model to ../../working/IIIT.h5\nEpoch 41/200\n32/32 [==============================] - 38s 1s/step - loss: 0.8959 - accuracy: 0.7384 - val_loss: 1.1321 - val_accuracy: 0.6734\n\nEpoch 00041: val_accuracy improved from 0.66734 to 0.67339, saving model to ../../working/IIIT.h5\nEpoch 42/200\n32/32 [==============================] - 39s 1s/step - loss: 0.8821 - accuracy: 0.7465 - val_loss: 1.1538 - val_accuracy: 0.6633\n\nEpoch 00042: val_accuracy did not improve from 0.67339\nEpoch 43/200\n32/32 [==============================] - 39s 1s/step - loss: 0.8773 - accuracy: 0.7525 - val_loss: 1.2140 - val_accuracy: 0.6230\n\nEpoch 00043: val_accuracy did not improve from 0.67339\nEpoch 44/200\n32/32 [==============================] - 40s 1s/step - loss: 0.8551 - accuracy: 0.7450 - val_loss: 1.1670 - val_accuracy: 0.6653\n\nEpoch 00044: val_accuracy did not improve from 0.67339\nEpoch 45/200\n32/32 [==============================] - 39s 1s/step - loss: 0.8031 - accuracy: 0.7666 - val_loss: 1.0499 - val_accuracy: 0.6996\n\nEpoch 00045: val_accuracy improved from 0.67339 to 0.69960, saving model to ../../working/IIIT.h5\nEpoch 46/200\n32/32 [==============================] - 39s 1s/step - loss: 0.7803 - accuracy: 0.7818 - val_loss: 1.0856 - val_accuracy: 0.6653\n\nEpoch 00046: val_accuracy did not improve from 0.69960\nEpoch 47/200\n32/32 [==============================] - 39s 1s/step - loss: 0.7952 - accuracy: 0.7747 - val_loss: 1.1065 - val_accuracy: 0.6673\n\nEpoch 00047: val_accuracy did not improve from 0.69960\nEpoch 48/200\n32/32 [==============================] - 40s 1s/step - loss: 0.7828 - accuracy: 0.7611 - val_loss: 1.1005 - val_accuracy: 0.6815\n\nEpoch 00048: val_accuracy did not improve from 0.69960\nEpoch 49/200\n32/32 [==============================] - 40s 1s/step - loss: 0.7713 - accuracy: 0.7712 - val_loss: 1.1040 - val_accuracy: 0.6794\n\nEpoch 00049: val_accuracy did not improve from 0.69960\nEpoch 50/200\n32/32 [==============================] - 40s 1s/step - loss: 0.7235 - accuracy: 0.7918 - val_loss: 1.0438 - val_accuracy: 0.6875\n\nEpoch 00050: val_accuracy did not improve from 0.69960\nEpoch 51/200\n32/32 [==============================] - 40s 1s/step - loss: 0.7157 - accuracy: 0.7954 - val_loss: 1.0416 - val_accuracy: 0.6956\n\nEpoch 00051: val_accuracy did not improve from 0.69960\nEpoch 52/200\n32/32 [==============================] - 40s 1s/step - loss: 0.7075 - accuracy: 0.7928 - val_loss: 1.0591 - val_accuracy: 0.6935\n\nEpoch 00052: val_accuracy did not improve from 0.69960\nEpoch 53/200\n32/32 [==============================] - 40s 1s/step - loss: 0.6836 - accuracy: 0.7913 - val_loss: 1.0782 - val_accuracy: 0.6855\n\nEpoch 00053: val_accuracy did not improve from 0.69960\nEpoch 54/200\n32/32 [==============================] - 40s 1s/step - loss: 0.6759 - accuracy: 0.7969 - val_loss: 1.0333 - val_accuracy: 0.6653\n\nEpoch 00054: val_accuracy did not improve from 0.69960\nEpoch 55/200\n32/32 [==============================] - 40s 1s/step - loss: 0.6414 - accuracy: 0.8080 - val_loss: 1.0280 - val_accuracy: 0.6956\n\nEpoch 00055: val_accuracy did not improve from 0.69960\nEpoch 56/200\n32/32 [==============================] - 40s 1s/step - loss: 0.6279 - accuracy: 0.8150 - val_loss: 1.0299 - val_accuracy: 0.6996\n\nEpoch 00056: val_accuracy did not improve from 0.69960\nEpoch 57/200\n32/32 [==============================] - 40s 1s/step - loss: 0.6455 - accuracy: 0.8105 - val_loss: 1.0166 - val_accuracy: 0.6956\n\nEpoch 00057: val_accuracy did not improve from 0.69960\nEpoch 58/200\n32/32 [==============================] - 40s 1s/step - loss: 0.6068 - accuracy: 0.8271 - val_loss: 1.1464 - val_accuracy: 0.6895\n\nEpoch 00058: val_accuracy did not improve from 0.69960\nEpoch 59/200\n32/32 [==============================] - 40s 1s/step - loss: 0.6025 - accuracy: 0.8256 - val_loss: 0.9859 - val_accuracy: 0.7056\n\nEpoch 00059: val_accuracy improved from 0.69960 to 0.70565, saving model to ../../working/IIIT.h5\nEpoch 60/200\n32/32 [==============================] - 40s 1s/step - loss: 0.5956 - accuracy: 0.8206 - val_loss: 0.9675 - val_accuracy: 0.7056\n\nEpoch 00060: val_accuracy did not improve from 0.70565\nEpoch 61/200\n32/32 [==============================] - 40s 1s/step - loss: 0.6166 - accuracy: 0.8231 - val_loss: 1.0169 - val_accuracy: 0.6935\n\nEpoch 00061: val_accuracy did not improve from 0.70565\nEpoch 62/200\n32/32 [==============================] - 41s 1s/step - loss: 0.5566 - accuracy: 0.8306 - val_loss: 1.0098 - val_accuracy: 0.7036\n\nEpoch 00062: val_accuracy did not improve from 0.70565\nEpoch 63/200\n32/32 [==============================] - 40s 1s/step - loss: 0.5470 - accuracy: 0.8382 - val_loss: 1.0391 - val_accuracy: 0.6895\n\nEpoch 00063: val_accuracy did not improve from 0.70565\nEpoch 64/200\n32/32 [==============================] - 40s 1s/step - loss: 0.5827 - accuracy: 0.8286 - val_loss: 0.9457 - val_accuracy: 0.7117\n\nEpoch 00064: val_accuracy improved from 0.70565 to 0.71169, saving model to ../../working/IIIT.h5\nEpoch 65/200\n32/32 [==============================] - 40s 1s/step - loss: 0.5346 - accuracy: 0.8342 - val_loss: 0.9234 - val_accuracy: 0.7117\n\nEpoch 00065: val_accuracy did not improve from 0.71169\nEpoch 66/200\n32/32 [==============================] - 41s 1s/step - loss: 0.5022 - accuracy: 0.8564 - val_loss: 0.9259 - val_accuracy: 0.7238\n\nEpoch 00066: val_accuracy improved from 0.71169 to 0.72379, saving model to ../../working/IIIT.h5\nEpoch 67/200\n32/32 [==============================] - 40s 1s/step - loss: 0.5074 - accuracy: 0.8553 - val_loss: 0.9749 - val_accuracy: 0.7198\n\nEpoch 00067: val_accuracy did not improve from 0.72379\nEpoch 68/200\n32/32 [==============================] - 40s 1s/step - loss: 0.4847 - accuracy: 0.8589 - val_loss: 0.9037 - val_accuracy: 0.7238\n\nEpoch 00068: val_accuracy did not improve from 0.72379\nEpoch 69/200\n32/32 [==============================] - 40s 1s/step - loss: 0.4751 - accuracy: 0.8629 - val_loss: 0.9607 - val_accuracy: 0.7117\n\nEpoch 00069: val_accuracy did not improve from 0.72379\nEpoch 70/200\n32/32 [==============================] - 40s 1s/step - loss: 0.4780 - accuracy: 0.8594 - val_loss: 0.9487 - val_accuracy: 0.7036\n\nEpoch 00070: val_accuracy did not improve from 0.72379\nEpoch 71/200\n32/32 [==============================] - 40s 1s/step - loss: 0.4823 - accuracy: 0.8513 - val_loss: 0.9837 - val_accuracy: 0.7036\n\nEpoch 00071: val_accuracy did not improve from 0.72379\nEpoch 72/200\n32/32 [==============================] - 40s 1s/step - loss: 0.4621 - accuracy: 0.8654 - val_loss: 0.9762 - val_accuracy: 0.7137\n\nEpoch 00072: val_accuracy did not improve from 0.72379\nEpoch 73/200\n32/32 [==============================] - 40s 1s/step - loss: 0.4568 - accuracy: 0.8629 - val_loss: 0.9481 - val_accuracy: 0.7198\n\nEpoch 00073: val_accuracy did not improve from 0.72379\nEpoch 74/200\n32/32 [==============================] - 40s 1s/step - loss: 0.4276 - accuracy: 0.8710 - val_loss: 0.9587 - val_accuracy: 0.7036\n\nEpoch 00074: val_accuracy did not improve from 0.72379\nEpoch 75/200\n32/32 [==============================] - 40s 1s/step - loss: 0.4424 - accuracy: 0.8720 - val_loss: 0.9217 - val_accuracy: 0.7177\n\nEpoch 00075: val_accuracy did not improve from 0.72379\nEpoch 76/200\n32/32 [==============================] - 40s 1s/step - loss: 0.4780 - accuracy: 0.8574 - val_loss: 0.8888 - val_accuracy: 0.7359\n\nEpoch 00076: val_accuracy improved from 0.72379 to 0.73589, saving model to ../../working/IIIT.h5\nEpoch 77/200\n32/32 [==============================] - 40s 1s/step - loss: 0.4298 - accuracy: 0.8750 - val_loss: 0.9362 - val_accuracy: 0.7177\n\nEpoch 00077: val_accuracy did not improve from 0.73589\nEpoch 78/200\n32/32 [==============================] - 40s 1s/step - loss: 0.4225 - accuracy: 0.8780 - val_loss: 0.8819 - val_accuracy: 0.7198\n\nEpoch 00078: val_accuracy did not improve from 0.73589\nEpoch 79/200\n32/32 [==============================] - 40s 1s/step - loss: 0.4165 - accuracy: 0.8780 - val_loss: 0.9315 - val_accuracy: 0.7278\n\nEpoch 00079: val_accuracy did not improve from 0.73589\nEpoch 80/200\n32/32 [==============================] - 40s 1s/step - loss: 0.4082 - accuracy: 0.8765 - val_loss: 0.9523 - val_accuracy: 0.7137\n\nEpoch 00080: val_accuracy did not improve from 0.73589\nEpoch 81/200\n32/32 [==============================] - 40s 1s/step - loss: 0.3990 - accuracy: 0.8831 - val_loss: 0.8937 - val_accuracy: 0.7298\n\nEpoch 00081: val_accuracy did not improve from 0.73589\nEpoch 82/200\n32/32 [==============================] - 40s 1s/step - loss: 0.4008 - accuracy: 0.8826 - val_loss: 0.9198 - val_accuracy: 0.7157\n\nEpoch 00082: val_accuracy did not improve from 0.73589\nEpoch 83/200\n32/32 [==============================] - 39s 1s/step - loss: 0.3916 - accuracy: 0.8841 - val_loss: 0.9578 - val_accuracy: 0.7117\n\nEpoch 00083: val_accuracy did not improve from 0.73589\nEpoch 84/200\n32/32 [==============================] - 40s 1s/step - loss: 0.3958 - accuracy: 0.8755 - val_loss: 1.0111 - val_accuracy: 0.7036\n\nEpoch 00084: val_accuracy did not improve from 0.73589\nEpoch 85/200\n32/32 [==============================] - 40s 1s/step - loss: 0.3790 - accuracy: 0.8931 - val_loss: 0.9201 - val_accuracy: 0.7097\n\nEpoch 00085: val_accuracy did not improve from 0.73589\nEpoch 86/200\n32/32 [==============================] - 40s 1s/step - loss: 0.3520 - accuracy: 0.8992 - val_loss: 0.8809 - val_accuracy: 0.7460\n\nEpoch 00086: val_accuracy improved from 0.73589 to 0.74597, saving model to ../../working/IIIT.h5\nEpoch 87/200\n32/32 [==============================] - 40s 1s/step - loss: 0.3494 - accuracy: 0.8977 - val_loss: 0.9028 - val_accuracy: 0.7419\n\nEpoch 00087: val_accuracy did not improve from 0.74597\nEpoch 88/200\n32/32 [==============================] - 40s 1s/step - loss: 0.3349 - accuracy: 0.9032 - val_loss: 0.9187 - val_accuracy: 0.7177\n\nEpoch 00088: val_accuracy did not improve from 0.74597\nEpoch 89/200\n32/32 [==============================] - 40s 1s/step - loss: 0.3577 - accuracy: 0.8997 - val_loss: 0.9630 - val_accuracy: 0.7137\n\nEpoch 00089: val_accuracy did not improve from 0.74597\nEpoch 90/200\n32/32 [==============================] - 40s 1s/step - loss: 0.3424 - accuracy: 0.8967 - val_loss: 0.8765 - val_accuracy: 0.7298\n\nEpoch 00090: val_accuracy did not improve from 0.74597\nEpoch 91/200\n32/32 [==============================] - 40s 1s/step - loss: 0.3335 - accuracy: 0.9012 - val_loss: 0.8969 - val_accuracy: 0.7379\n\nEpoch 00091: val_accuracy did not improve from 0.74597\nEpoch 92/200\n32/32 [==============================] - 40s 1s/step - loss: 0.3203 - accuracy: 0.9103 - val_loss: 0.9831 - val_accuracy: 0.7036\n\nEpoch 00092: val_accuracy did not improve from 0.74597\nEpoch 93/200\n32/32 [==============================] - 40s 1s/step - loss: 0.3282 - accuracy: 0.9073 - val_loss: 0.9359 - val_accuracy: 0.7238\n\nEpoch 00093: val_accuracy did not improve from 0.74597\nEpoch 94/200\n32/32 [==============================] - 40s 1s/step - loss: 0.3311 - accuracy: 0.8987 - val_loss: 0.9514 - val_accuracy: 0.7319\n\nEpoch 00094: val_accuracy did not improve from 0.74597\nEpoch 95/200\n32/32 [==============================] - 40s 1s/step - loss: 0.3220 - accuracy: 0.9113 - val_loss: 0.8690 - val_accuracy: 0.7460\n\nEpoch 00095: val_accuracy did not improve from 0.74597\nEpoch 96/200\n32/32 [==============================] - 40s 1s/step - loss: 0.3075 - accuracy: 0.9083 - val_loss: 0.8403 - val_accuracy: 0.7540\n\nEpoch 00096: val_accuracy improved from 0.74597 to 0.75403, saving model to ../../working/IIIT.h5\nEpoch 97/200\n32/32 [==============================] - 40s 1s/step - loss: 0.3114 - accuracy: 0.9037 - val_loss: 0.9184 - val_accuracy: 0.7218\n\nEpoch 00097: val_accuracy did not improve from 0.75403\nEpoch 98/200\n32/32 [==============================] - 40s 1s/step - loss: 0.3117 - accuracy: 0.9133 - val_loss: 0.8567 - val_accuracy: 0.7419\n\nEpoch 00098: val_accuracy did not improve from 0.75403\nEpoch 99/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2968 - accuracy: 0.9209 - val_loss: 0.8922 - val_accuracy: 0.7359\n\nEpoch 00099: val_accuracy did not improve from 0.75403\nEpoch 100/200\n32/32 [==============================] - 40s 1s/step - loss: 0.3165 - accuracy: 0.9098 - val_loss: 0.8964 - val_accuracy: 0.7460\n\nEpoch 00100: val_accuracy did not improve from 0.75403\nEpoch 101/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2945 - accuracy: 0.9178 - val_loss: 0.9154 - val_accuracy: 0.7298\n\nEpoch 00101: val_accuracy did not improve from 0.75403\nEpoch 102/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2626 - accuracy: 0.9229 - val_loss: 0.9675 - val_accuracy: 0.7077\n\nEpoch 00102: val_accuracy did not improve from 0.75403\nEpoch 103/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2854 - accuracy: 0.9178 - val_loss: 0.8970 - val_accuracy: 0.7278\n\nEpoch 00103: val_accuracy did not improve from 0.75403\nEpoch 104/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2726 - accuracy: 0.9224 - val_loss: 0.9244 - val_accuracy: 0.7157\n\nEpoch 00104: val_accuracy did not improve from 0.75403\nEpoch 105/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2928 - accuracy: 0.9158 - val_loss: 0.8695 - val_accuracy: 0.7359\n\nEpoch 00105: val_accuracy did not improve from 0.75403\nEpoch 106/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2605 - accuracy: 0.9259 - val_loss: 0.9384 - val_accuracy: 0.7319\n\nEpoch 00106: val_accuracy did not improve from 0.75403\nEpoch 107/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2889 - accuracy: 0.9168 - val_loss: 0.9268 - val_accuracy: 0.7258\n\nEpoch 00107: val_accuracy did not improve from 0.75403\nEpoch 108/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2711 - accuracy: 0.9229 - val_loss: 0.9515 - val_accuracy: 0.7379\n\nEpoch 00108: val_accuracy did not improve from 0.75403\nEpoch 109/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2692 - accuracy: 0.9153 - val_loss: 0.9695 - val_accuracy: 0.7097\n\nEpoch 00109: val_accuracy did not improve from 0.75403\nEpoch 110/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2650 - accuracy: 0.9254 - val_loss: 0.9290 - val_accuracy: 0.7339\n\nEpoch 00110: val_accuracy did not improve from 0.75403\nEpoch 111/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2605 - accuracy: 0.9249 - val_loss: 0.8724 - val_accuracy: 0.7520\n\nEpoch 00111: val_accuracy did not improve from 0.75403\nEpoch 112/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2494 - accuracy: 0.9254 - val_loss: 0.8311 - val_accuracy: 0.7460\n\nEpoch 00112: val_accuracy did not improve from 0.75403\nEpoch 113/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2419 - accuracy: 0.9330 - val_loss: 0.9009 - val_accuracy: 0.7339\n\nEpoch 00113: val_accuracy did not improve from 0.75403\nEpoch 114/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2578 - accuracy: 0.9234 - val_loss: 0.8692 - val_accuracy: 0.7520\n\nEpoch 00114: val_accuracy did not improve from 0.75403\nEpoch 115/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2312 - accuracy: 0.9345 - val_loss: 0.8687 - val_accuracy: 0.7560\n\nEpoch 00115: val_accuracy improved from 0.75403 to 0.75605, saving model to ../../working/IIIT.h5\nEpoch 116/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2346 - accuracy: 0.9335 - val_loss: 0.9776 - val_accuracy: 0.7419\n\nEpoch 00116: val_accuracy did not improve from 0.75605\nEpoch 117/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2393 - accuracy: 0.9304 - val_loss: 0.9393 - val_accuracy: 0.7440\n\nEpoch 00117: val_accuracy did not improve from 0.75605\nEpoch 118/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2497 - accuracy: 0.9259 - val_loss: 0.8800 - val_accuracy: 0.7399\n\nEpoch 00118: val_accuracy did not improve from 0.75605\nEpoch 119/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2297 - accuracy: 0.9400 - val_loss: 0.8604 - val_accuracy: 0.7480\n\nEpoch 00119: val_accuracy did not improve from 0.75605\nEpoch 120/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2357 - accuracy: 0.9340 - val_loss: 0.9469 - val_accuracy: 0.7238\n\nEpoch 00120: val_accuracy did not improve from 0.75605\nEpoch 121/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2123 - accuracy: 0.9446 - val_loss: 0.9029 - val_accuracy: 0.7419\n\nEpoch 00121: val_accuracy did not improve from 0.75605\nEpoch 122/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2210 - accuracy: 0.9395 - val_loss: 0.8914 - val_accuracy: 0.7359\n\nEpoch 00122: val_accuracy did not improve from 0.75605\nEpoch 123/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2157 - accuracy: 0.9405 - val_loss: 0.9140 - val_accuracy: 0.7621\n\nEpoch 00123: val_accuracy improved from 0.75605 to 0.76210, saving model to ../../working/IIIT.h5\nEpoch 124/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2173 - accuracy: 0.9385 - val_loss: 0.9443 - val_accuracy: 0.7339\n\nEpoch 00124: val_accuracy did not improve from 0.76210\nEpoch 125/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2177 - accuracy: 0.9380 - val_loss: 0.9508 - val_accuracy: 0.7218\n\nEpoch 00125: val_accuracy did not improve from 0.76210\nEpoch 126/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2222 - accuracy: 0.9390 - val_loss: 0.8733 - val_accuracy: 0.7359\n\nEpoch 00126: val_accuracy did not improve from 0.76210\nEpoch 127/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2129 - accuracy: 0.9345 - val_loss: 0.9986 - val_accuracy: 0.7218\n\nEpoch 00127: val_accuracy did not improve from 0.76210\nEpoch 128/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2038 - accuracy: 0.9435 - val_loss: 0.9089 - val_accuracy: 0.7399\n\nEpoch 00128: val_accuracy did not improve from 0.76210\nEpoch 129/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2286 - accuracy: 0.9350 - val_loss: 0.9918 - val_accuracy: 0.7056\n\nEpoch 00129: val_accuracy did not improve from 0.76210\nEpoch 130/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2181 - accuracy: 0.9335 - val_loss: 0.8956 - val_accuracy: 0.7379\n\nEpoch 00130: val_accuracy did not improve from 0.76210\nEpoch 131/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1888 - accuracy: 0.9516 - val_loss: 0.9227 - val_accuracy: 0.7177\n\nEpoch 00131: val_accuracy did not improve from 0.76210\nEpoch 132/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2098 - accuracy: 0.9355 - val_loss: 0.9382 - val_accuracy: 0.7319\n\nEpoch 00132: val_accuracy did not improve from 0.76210\nEpoch 133/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2054 - accuracy: 0.9461 - val_loss: 0.8714 - val_accuracy: 0.7601\n\nEpoch 00133: val_accuracy did not improve from 0.76210\nEpoch 134/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1955 - accuracy: 0.9451 - val_loss: 0.9470 - val_accuracy: 0.7399\n\nEpoch 00134: val_accuracy did not improve from 0.76210\nEpoch 135/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2024 - accuracy: 0.9405 - val_loss: 0.9724 - val_accuracy: 0.7077\n\nEpoch 00135: val_accuracy did not improve from 0.76210\nEpoch 136/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1821 - accuracy: 0.9511 - val_loss: 0.9501 - val_accuracy: 0.7339\n\nEpoch 00136: val_accuracy did not improve from 0.76210\nEpoch 137/200\n32/32 [==============================] - 40s 1s/step - loss: 0.2032 - accuracy: 0.9405 - val_loss: 0.9204 - val_accuracy: 0.7319\n\nEpoch 00137: val_accuracy did not improve from 0.76210\nEpoch 138/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1881 - accuracy: 0.9471 - val_loss: 0.9361 - val_accuracy: 0.7298\n\nEpoch 00138: val_accuracy did not improve from 0.76210\nEpoch 139/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1798 - accuracy: 0.9536 - val_loss: 0.9135 - val_accuracy: 0.7298\n\nEpoch 00139: val_accuracy did not improve from 0.76210\nEpoch 140/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1993 - accuracy: 0.9441 - val_loss: 0.8979 - val_accuracy: 0.7520\n\nEpoch 00140: val_accuracy did not improve from 0.76210\nEpoch 141/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1920 - accuracy: 0.9456 - val_loss: 0.8418 - val_accuracy: 0.7560\n\nEpoch 00141: val_accuracy did not improve from 0.76210\nEpoch 142/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1870 - accuracy: 0.9501 - val_loss: 0.9292 - val_accuracy: 0.7339\n\nEpoch 00142: val_accuracy did not improve from 0.76210\nEpoch 143/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1875 - accuracy: 0.9471 - val_loss: 0.8666 - val_accuracy: 0.7339\n\nEpoch 00143: val_accuracy did not improve from 0.76210\nEpoch 144/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1803 - accuracy: 0.9486 - val_loss: 0.8939 - val_accuracy: 0.7520\n\nEpoch 00144: val_accuracy did not improve from 0.76210\nEpoch 145/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1656 - accuracy: 0.9592 - val_loss: 0.9046 - val_accuracy: 0.7419\n\nEpoch 00145: val_accuracy did not improve from 0.76210\nEpoch 146/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1653 - accuracy: 0.9521 - val_loss: 0.9066 - val_accuracy: 0.7399\n\nEpoch 00146: val_accuracy did not improve from 0.76210\nEpoch 147/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1682 - accuracy: 0.9541 - val_loss: 0.9332 - val_accuracy: 0.7399\n\nEpoch 00147: val_accuracy did not improve from 0.76210\nEpoch 148/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1547 - accuracy: 0.9561 - val_loss: 0.9059 - val_accuracy: 0.7319\n\nEpoch 00148: val_accuracy did not improve from 0.76210\nEpoch 149/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1550 - accuracy: 0.9567 - val_loss: 0.8968 - val_accuracy: 0.7379\n\nEpoch 00149: val_accuracy did not improve from 0.76210\nEpoch 150/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1647 - accuracy: 0.9541 - val_loss: 0.9192 - val_accuracy: 0.7198\n\nEpoch 00150: val_accuracy did not improve from 0.76210\nEpoch 151/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1676 - accuracy: 0.9511 - val_loss: 0.9540 - val_accuracy: 0.7379\n\nEpoch 00151: val_accuracy did not improve from 0.76210\nEpoch 152/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1584 - accuracy: 0.9556 - val_loss: 0.8930 - val_accuracy: 0.7460\n\nEpoch 00152: val_accuracy did not improve from 0.76210\nEpoch 153/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1486 - accuracy: 0.9597 - val_loss: 0.9139 - val_accuracy: 0.7440\n\nEpoch 00153: val_accuracy did not improve from 0.76210\nEpoch 154/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1658 - accuracy: 0.9541 - val_loss: 0.9201 - val_accuracy: 0.7480\n\nEpoch 00154: val_accuracy did not improve from 0.76210\nEpoch 155/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1580 - accuracy: 0.9501 - val_loss: 0.8785 - val_accuracy: 0.7440\n\nEpoch 00155: val_accuracy did not improve from 0.76210\nEpoch 156/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1522 - accuracy: 0.9582 - val_loss: 0.9074 - val_accuracy: 0.7440\n\nEpoch 00156: val_accuracy did not improve from 0.76210\nEpoch 157/200\n32/32 [==============================] - 39s 1s/step - loss: 0.1777 - accuracy: 0.9446 - val_loss: 0.9114 - val_accuracy: 0.7359\n\nEpoch 00157: val_accuracy did not improve from 0.76210\nEpoch 158/200\n32/32 [==============================] - 40s 1s/step - loss: 0.1636 - accuracy: 0.9536 - val_loss: 0.9230 - val_accuracy: 0.7399\n\nEpoch 00158: val_accuracy did not improve from 0.76210\nEpoch 159/200\n32/32 [==============================] - 39s 1s/step - loss: 0.1533 - accuracy: 0.9602 - val_loss: 0.9040 - val_accuracy: 0.7258\n\nEpoch 00159: val_accuracy did not improve from 0.76210\nEpoch 160/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1430 - accuracy: 0.9612 - val_loss: 0.9269 - val_accuracy: 0.7319\n\nEpoch 00160: val_accuracy did not improve from 0.76210\nEpoch 161/200\n32/32 [==============================] - 39s 1s/step - loss: 0.1451 - accuracy: 0.9587 - val_loss: 0.8887 - val_accuracy: 0.7520\n\nEpoch 00161: val_accuracy did not improve from 0.76210\nEpoch 162/200\n32/32 [==============================] - 39s 1s/step - loss: 0.1435 - accuracy: 0.9577 - val_loss: 0.9249 - val_accuracy: 0.7218\n\nEpoch 00162: val_accuracy did not improve from 0.76210\nEpoch 163/200\n32/32 [==============================] - 39s 1s/step - loss: 0.1315 - accuracy: 0.9713 - val_loss: 0.9500 - val_accuracy: 0.7399\n\nEpoch 00163: val_accuracy did not improve from 0.76210\nEpoch 164/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1513 - accuracy: 0.9617 - val_loss: 0.8995 - val_accuracy: 0.7601\n\nEpoch 00164: val_accuracy did not improve from 0.76210\nEpoch 165/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1540 - accuracy: 0.9577 - val_loss: 0.9405 - val_accuracy: 0.7399\n\nEpoch 00165: val_accuracy did not improve from 0.76210\nEpoch 166/200\n32/32 [==============================] - 39s 1s/step - loss: 0.1380 - accuracy: 0.9642 - val_loss: 0.9611 - val_accuracy: 0.7379\n\nEpoch 00166: val_accuracy did not improve from 0.76210\nEpoch 167/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1310 - accuracy: 0.9703 - val_loss: 0.9025 - val_accuracy: 0.7298\n\nEpoch 00167: val_accuracy did not improve from 0.76210\nEpoch 168/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1424 - accuracy: 0.9637 - val_loss: 0.9457 - val_accuracy: 0.7238\n\nEpoch 00168: val_accuracy did not improve from 0.76210\nEpoch 169/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1404 - accuracy: 0.9637 - val_loss: 0.9193 - val_accuracy: 0.7298\n\nEpoch 00169: val_accuracy did not improve from 0.76210\nEpoch 170/200\n32/32 [==============================] - 39s 1s/step - loss: 0.1393 - accuracy: 0.9617 - val_loss: 0.9381 - val_accuracy: 0.7238\n\nEpoch 00170: val_accuracy did not improve from 0.76210\nEpoch 171/200\n32/32 [==============================] - 39s 1s/step - loss: 0.1359 - accuracy: 0.9688 - val_loss: 0.9499 - val_accuracy: 0.7500\n\nEpoch 00171: val_accuracy did not improve from 0.76210\nEpoch 172/200\n32/32 [==============================] - 39s 1s/step - loss: 0.1289 - accuracy: 0.9688 - val_loss: 0.9644 - val_accuracy: 0.7419\n\nEpoch 00172: val_accuracy did not improve from 0.76210\nEpoch 173/200\n32/32 [==============================] - 37s 1s/step - loss: 0.1307 - accuracy: 0.9627 - val_loss: 0.9453 - val_accuracy: 0.7319\n\nEpoch 00173: val_accuracy did not improve from 0.76210\nEpoch 174/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1285 - accuracy: 0.9647 - val_loss: 0.8738 - val_accuracy: 0.7520\n\nEpoch 00174: val_accuracy did not improve from 0.76210\nEpoch 175/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1210 - accuracy: 0.9713 - val_loss: 0.8970 - val_accuracy: 0.7419\n\nEpoch 00175: val_accuracy did not improve from 0.76210\nEpoch 176/200\n32/32 [==============================] - 39s 1s/step - loss: 0.1341 - accuracy: 0.9617 - val_loss: 1.0357 - val_accuracy: 0.7198\n\nEpoch 00176: val_accuracy did not improve from 0.76210\nEpoch 177/200\n32/32 [==============================] - 39s 1s/step - loss: 0.1261 - accuracy: 0.9662 - val_loss: 0.9676 - val_accuracy: 0.7339\n\nEpoch 00177: val_accuracy did not improve from 0.76210\nEpoch 178/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1278 - accuracy: 0.9698 - val_loss: 0.8689 - val_accuracy: 0.7500\n\nEpoch 00178: val_accuracy did not improve from 0.76210\nEpoch 179/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1138 - accuracy: 0.9703 - val_loss: 0.9176 - val_accuracy: 0.7339\n\nEpoch 00179: val_accuracy did not improve from 0.76210\nEpoch 180/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1186 - accuracy: 0.9693 - val_loss: 0.8802 - val_accuracy: 0.7520\n\nEpoch 00180: val_accuracy did not improve from 0.76210\nEpoch 181/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1245 - accuracy: 0.9672 - val_loss: 0.9744 - val_accuracy: 0.7319\n\nEpoch 00181: val_accuracy did not improve from 0.76210\nEpoch 182/200\n32/32 [==============================] - 39s 1s/step - loss: 0.1200 - accuracy: 0.9677 - val_loss: 0.9290 - val_accuracy: 0.7460\n\nEpoch 00182: val_accuracy did not improve from 0.76210\nEpoch 183/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1160 - accuracy: 0.9662 - val_loss: 0.9803 - val_accuracy: 0.7359\n\nEpoch 00183: val_accuracy did not improve from 0.76210\nEpoch 184/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1278 - accuracy: 0.9587 - val_loss: 0.9322 - val_accuracy: 0.7399\n\nEpoch 00184: val_accuracy did not improve from 0.76210\nEpoch 185/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1114 - accuracy: 0.9728 - val_loss: 0.9014 - val_accuracy: 0.7540\n\nEpoch 00185: val_accuracy did not improve from 0.76210\nEpoch 186/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1246 - accuracy: 0.9632 - val_loss: 0.8967 - val_accuracy: 0.7480\n\nEpoch 00186: val_accuracy did not improve from 0.76210\nEpoch 187/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1035 - accuracy: 0.9743 - val_loss: 0.9334 - val_accuracy: 0.7278\n\nEpoch 00187: val_accuracy did not improve from 0.76210\nEpoch 188/200\n32/32 [==============================] - 39s 1s/step - loss: 0.1103 - accuracy: 0.9758 - val_loss: 0.8739 - val_accuracy: 0.7460\n\nEpoch 00188: val_accuracy did not improve from 0.76210\nEpoch 189/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1167 - accuracy: 0.9647 - val_loss: 0.9383 - val_accuracy: 0.7298\n\nEpoch 00189: val_accuracy did not improve from 0.76210\nEpoch 190/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1077 - accuracy: 0.9748 - val_loss: 0.9484 - val_accuracy: 0.7399\n\nEpoch 00190: val_accuracy did not improve from 0.76210\nEpoch 191/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1108 - accuracy: 0.9733 - val_loss: 0.9646 - val_accuracy: 0.7399\n\nEpoch 00191: val_accuracy did not improve from 0.76210\nEpoch 192/200\n32/32 [==============================] - 39s 1s/step - loss: 0.1050 - accuracy: 0.9753 - val_loss: 0.9067 - val_accuracy: 0.7480\n\nEpoch 00192: val_accuracy did not improve from 0.76210\nEpoch 193/200\n32/32 [==============================] - 39s 1s/step - loss: 0.1096 - accuracy: 0.9693 - val_loss: 0.9335 - val_accuracy: 0.7298\n\nEpoch 00193: val_accuracy did not improve from 0.76210\nEpoch 194/200\n32/32 [==============================] - 39s 1s/step - loss: 0.1197 - accuracy: 0.9713 - val_loss: 0.8738 - val_accuracy: 0.7440\n\nEpoch 00194: val_accuracy did not improve from 0.76210\nEpoch 195/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1228 - accuracy: 0.9662 - val_loss: 0.9127 - val_accuracy: 0.7339\n\nEpoch 00195: val_accuracy did not improve from 0.76210\nEpoch 196/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1037 - accuracy: 0.9748 - val_loss: 0.9236 - val_accuracy: 0.7258\n\nEpoch 00196: val_accuracy did not improve from 0.76210\nEpoch 197/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1087 - accuracy: 0.9738 - val_loss: 0.9576 - val_accuracy: 0.7399\n\nEpoch 00197: val_accuracy did not improve from 0.76210\nEpoch 198/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1018 - accuracy: 0.9773 - val_loss: 0.8851 - val_accuracy: 0.7500\n\nEpoch 00198: val_accuracy did not improve from 0.76210\nEpoch 199/200\n32/32 [==============================] - 38s 1s/step - loss: 0.1243 - accuracy: 0.9657 - val_loss: 0.8955 - val_accuracy: 0.7520\n\nEpoch 00199: val_accuracy did not improve from 0.76210\nEpoch 200/200\n32/32 [==============================] - 38s 1s/step - loss: 0.0937 - accuracy: 0.9783 - val_loss: 0.9466 - val_accuracy: 0.7319\n\nEpoch 00200: val_accuracy did not improve from 0.76210\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f1d505fef90>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Max accuracy of 76.210% on val data","metadata":{}},{"cell_type":"markdown","source":"# I have used the below model for my referencial purpose (dont consider it as part of project). This was just to check the performance of VGG-16 model which was trained from scratch ( I have not used the pretrained weights). The accuracy on val data is less than compared to our chosen model. (Note: val_accuracy did not improve from 0.83669 denotes the val accuracy of our prev(main) model here.)\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nmodel1=Sequential()\nmodel1.add(VGG16(weights=None,include_top=False,input_shape=(240,180,1)))\nmodel1.add(Flatten())\nmodel1.add(Dense(250))\nmodel1.add(Activation(\"relu\"))\nmodel1.add(BatchNormalization())\nmodel1.add(Dropout(0.3))\nmodel1.add(Dense(62))\nmodel1.add(Activation(\"softmax\"))","metadata":{"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model1.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer= lr_schedule)\nmodel1.fit(train_it,steps_per_epoch=int(1984/62),epochs=200,validation_data=test_it,validation_steps=int(496/62),callbacks=callbacks_list)\n","metadata":{"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Epoch 1/200\n32/32 [==============================] - 33s 949ms/step - loss: 4.4864 - accuracy: 0.0137 - val_loss: 16.4830 - val_accuracy: 0.0121\n\nEpoch 00001: val_accuracy did not improve from 0.83669\nEpoch 2/200\n32/32 [==============================] - 30s 925ms/step - loss: 4.3228 - accuracy: 0.0101 - val_loss: 5.7447 - val_accuracy: 0.0121\n\nEpoch 00002: val_accuracy did not improve from 0.83669\nEpoch 3/200\n32/32 [==============================] - 29s 916ms/step - loss: 4.2959 - accuracy: 0.0170 - val_loss: 5.4110 - val_accuracy: 0.0161\n\nEpoch 00003: val_accuracy did not improve from 0.83669\nEpoch 4/200\n32/32 [==============================] - 29s 909ms/step - loss: 4.2653 - accuracy: 0.0202 - val_loss: 5.7179 - val_accuracy: 0.0081\n\nEpoch 00004: val_accuracy did not improve from 0.83669\nEpoch 5/200\n32/32 [==============================] - 29s 922ms/step - loss: 4.2073 - accuracy: 0.0127 - val_loss: 5.9367 - val_accuracy: 0.0202\n\nEpoch 00005: val_accuracy did not improve from 0.83669\nEpoch 6/200\n32/32 [==============================] - 29s 922ms/step - loss: 4.2460 - accuracy: 0.0142 - val_loss: 4.9673 - val_accuracy: 0.0161\n\nEpoch 00006: val_accuracy did not improve from 0.83669\nEpoch 7/200\n32/32 [==============================] - 28s 889ms/step - loss: 4.2428 - accuracy: 0.0176 - val_loss: 4.8766 - val_accuracy: 0.0161\n\nEpoch 00007: val_accuracy did not improve from 0.83669\nEpoch 8/200\n32/32 [==============================] - 28s 882ms/step - loss: 4.1957 - accuracy: 0.0239 - val_loss: 4.6963 - val_accuracy: 0.0121\n\nEpoch 00008: val_accuracy did not improve from 0.83669\nEpoch 9/200\n32/32 [==============================] - 28s 877ms/step - loss: 4.2386 - accuracy: 0.0169 - val_loss: 5.0172 - val_accuracy: 0.0202\n\nEpoch 00009: val_accuracy did not improve from 0.83669\nEpoch 10/200\n32/32 [==============================] - 28s 884ms/step - loss: 4.2159 - accuracy: 0.0142 - val_loss: 4.5665 - val_accuracy: 0.0161\n\nEpoch 00010: val_accuracy did not improve from 0.83669\nEpoch 11/200\n32/32 [==============================] - 28s 879ms/step - loss: 4.1920 - accuracy: 0.0147 - val_loss: 5.9587 - val_accuracy: 0.0081\n\nEpoch 00011: val_accuracy did not improve from 0.83669\nEpoch 12/200\n32/32 [==============================] - 28s 880ms/step - loss: 4.1679 - accuracy: 0.0337 - val_loss: 4.5482 - val_accuracy: 0.0242\n\nEpoch 00012: val_accuracy did not improve from 0.83669\nEpoch 13/200\n32/32 [==============================] - 28s 882ms/step - loss: 4.2173 - accuracy: 0.0169 - val_loss: 5.1739 - val_accuracy: 0.0161\n\nEpoch 00013: val_accuracy did not improve from 0.83669\nEpoch 14/200\n32/32 [==============================] - 28s 869ms/step - loss: 4.2169 - accuracy: 0.0204 - val_loss: 4.6156 - val_accuracy: 0.0242\n\nEpoch 00014: val_accuracy did not improve from 0.83669\nEpoch 15/200\n32/32 [==============================] - 29s 890ms/step - loss: 4.1885 - accuracy: 0.0195 - val_loss: 4.3361 - val_accuracy: 0.0323\n\nEpoch 00015: val_accuracy did not improve from 0.83669\nEpoch 16/200\n32/32 [==============================] - 28s 888ms/step - loss: 4.1667 - accuracy: 0.0108 - val_loss: 4.4713 - val_accuracy: 0.0242\n\nEpoch 00016: val_accuracy did not improve from 0.83669\nEpoch 17/200\n32/32 [==============================] - 29s 909ms/step - loss: 4.2002 - accuracy: 0.0130 - val_loss: 4.3849 - val_accuracy: 0.0161\n\nEpoch 00017: val_accuracy did not improve from 0.83669\nEpoch 18/200\n32/32 [==============================] - 29s 898ms/step - loss: 4.2033 - accuracy: 0.0144 - val_loss: 4.3679 - val_accuracy: 0.0121\n\nEpoch 00018: val_accuracy did not improve from 0.83669\nEpoch 19/200\n32/32 [==============================] - 29s 906ms/step - loss: 4.1934 - accuracy: 0.0185 - val_loss: 4.3192 - val_accuracy: 0.0161\n\nEpoch 00019: val_accuracy did not improve from 0.83669\nEpoch 20/200\n32/32 [==============================] - 29s 910ms/step - loss: 4.1807 - accuracy: 0.0174 - val_loss: 4.2239 - val_accuracy: 0.0242\n\nEpoch 00020: val_accuracy did not improve from 0.83669\nEpoch 21/200\n32/32 [==============================] - 29s 901ms/step - loss: 4.1839 - accuracy: 0.0154 - val_loss: 4.2468 - val_accuracy: 0.0121\n\nEpoch 00021: val_accuracy did not improve from 0.83669\nEpoch 22/200\n32/32 [==============================] - 29s 914ms/step - loss: 4.1767 - accuracy: 0.0152 - val_loss: 4.2534 - val_accuracy: 0.0121\n\nEpoch 00022: val_accuracy did not improve from 0.83669\nEpoch 23/200\n32/32 [==============================] - 29s 909ms/step - loss: 4.1493 - accuracy: 0.0165 - val_loss: 4.2291 - val_accuracy: 0.0121\n\nEpoch 00023: val_accuracy did not improve from 0.83669\nEpoch 24/200\n32/32 [==============================] - 28s 890ms/step - loss: 4.1835 - accuracy: 0.0166 - val_loss: 4.2160 - val_accuracy: 0.0121\n\nEpoch 00024: val_accuracy did not improve from 0.83669\nEpoch 25/200\n32/32 [==============================] - 30s 936ms/step - loss: 4.1749 - accuracy: 0.0113 - val_loss: 4.2187 - val_accuracy: 0.0202\n\nEpoch 00025: val_accuracy did not improve from 0.83669\nEpoch 26/200\n32/32 [==============================] - 30s 933ms/step - loss: 4.1551 - accuracy: 0.0087 - val_loss: 4.2392 - val_accuracy: 0.0202\n\nEpoch 00026: val_accuracy did not improve from 0.83669\nEpoch 27/200\n32/32 [==============================] - 30s 944ms/step - loss: 4.1704 - accuracy: 0.0280 - val_loss: 4.9114 - val_accuracy: 0.0000e+00\n\nEpoch 00027: val_accuracy did not improve from 0.83669\nEpoch 28/200\n32/32 [==============================] - 30s 925ms/step - loss: 4.1432 - accuracy: 0.0203 - val_loss: 4.2413 - val_accuracy: 0.0242\n\nEpoch 00028: val_accuracy did not improve from 0.83669\nEpoch 29/200\n32/32 [==============================] - 29s 904ms/step - loss: 4.1548 - accuracy: 0.0143 - val_loss: 4.1842 - val_accuracy: 0.0242\n\nEpoch 00029: val_accuracy did not improve from 0.83669\nEpoch 30/200\n32/32 [==============================] - 28s 886ms/step - loss: 4.1655 - accuracy: 0.0225 - val_loss: 4.1710 - val_accuracy: 0.0242\n\nEpoch 00030: val_accuracy did not improve from 0.83669\nEpoch 31/200\n32/32 [==============================] - 29s 900ms/step - loss: 4.1671 - accuracy: 0.0109 - val_loss: 4.1660 - val_accuracy: 0.0282\n\nEpoch 00031: val_accuracy did not improve from 0.83669\nEpoch 32/200\n32/32 [==============================] - 28s 891ms/step - loss: 4.1756 - accuracy: 0.0151 - val_loss: 4.1823 - val_accuracy: 0.0161\n\nEpoch 00032: val_accuracy did not improve from 0.83669\nEpoch 33/200\n32/32 [==============================] - 29s 898ms/step - loss: 4.1543 - accuracy: 0.0092 - val_loss: 4.1674 - val_accuracy: 0.0242\n\nEpoch 00033: val_accuracy did not improve from 0.83669\nEpoch 34/200\n32/32 [==============================] - 29s 905ms/step - loss: 4.1491 - accuracy: 0.0153 - val_loss: 4.1616 - val_accuracy: 0.0081\n\nEpoch 00034: val_accuracy did not improve from 0.83669\nEpoch 35/200\n32/32 [==============================] - 28s 876ms/step - loss: 4.1577 - accuracy: 0.0108 - val_loss: 4.1632 - val_accuracy: 0.0081\n\nEpoch 00035: val_accuracy did not improve from 0.83669\nEpoch 36/200\n32/32 [==============================] - 29s 897ms/step - loss: 4.1560 - accuracy: 0.0130 - val_loss: 4.1414 - val_accuracy: 0.0081\n\nEpoch 00036: val_accuracy did not improve from 0.83669\nEpoch 37/200\n32/32 [==============================] - 28s 891ms/step - loss: 4.1761 - accuracy: 0.0130 - val_loss: 4.1379 - val_accuracy: 0.0202\n\nEpoch 00037: val_accuracy did not improve from 0.83669\nEpoch 38/200\n32/32 [==============================] - 29s 889ms/step - loss: 4.1694 - accuracy: 0.0209 - val_loss: 4.1467 - val_accuracy: 0.0242\n\nEpoch 00038: val_accuracy did not improve from 0.83669\nEpoch 39/200\n32/32 [==============================] - 29s 901ms/step - loss: 4.1534 - accuracy: 0.0174 - val_loss: 4.1330 - val_accuracy: 0.0121\n\nEpoch 00039: val_accuracy did not improve from 0.83669\nEpoch 40/200\n32/32 [==============================] - 28s 890ms/step - loss: 4.1579 - accuracy: 0.0203 - val_loss: 4.1490 - val_accuracy: 0.0161\n\nEpoch 00040: val_accuracy did not improve from 0.83669\nEpoch 41/200\n32/32 [==============================] - 29s 894ms/step - loss: 4.1722 - accuracy: 0.0168 - val_loss: 4.1494 - val_accuracy: 0.0040\n\nEpoch 00041: val_accuracy did not improve from 0.83669\nEpoch 42/200\n32/32 [==============================] - 28s 879ms/step - loss: 4.1548 - accuracy: 0.0182 - val_loss: 4.1373 - val_accuracy: 0.0161\n\nEpoch 00042: val_accuracy did not improve from 0.83669\nEpoch 43/200\n32/32 [==============================] - 28s 875ms/step - loss: 4.1699 - accuracy: 0.0072 - val_loss: 4.1470 - val_accuracy: 0.0121\n\nEpoch 00043: val_accuracy did not improve from 0.83669\nEpoch 44/200\n32/32 [==============================] - 29s 898ms/step - loss: 4.1549 - accuracy: 0.0108 - val_loss: 4.1817 - val_accuracy: 0.0121\n\nEpoch 00044: val_accuracy did not improve from 0.83669\nEpoch 45/200\n32/32 [==============================] - 29s 901ms/step - loss: 4.1473 - accuracy: 0.0183 - val_loss: 4.2220 - val_accuracy: 0.0161\n\nEpoch 00045: val_accuracy did not improve from 0.83669\nEpoch 46/200\n32/32 [==============================] - 29s 899ms/step - loss: 4.1531 - accuracy: 0.0316 - val_loss: 4.1586 - val_accuracy: 0.0202\n\nEpoch 00046: val_accuracy did not improve from 0.83669\nEpoch 47/200\n32/32 [==============================] - 28s 892ms/step - loss: 4.1434 - accuracy: 0.0218 - val_loss: 4.2935 - val_accuracy: 0.0202\n\nEpoch 00047: val_accuracy did not improve from 0.83669\nEpoch 48/200\n32/32 [==============================] - 29s 893ms/step - loss: 4.1407 - accuracy: 0.0153 - val_loss: 4.5451 - val_accuracy: 0.0202\n\nEpoch 00048: val_accuracy did not improve from 0.83669\nEpoch 49/200\n32/32 [==============================] - 28s 879ms/step - loss: 4.1621 - accuracy: 0.0083 - val_loss: 4.1780 - val_accuracy: 0.0121\n\nEpoch 00049: val_accuracy did not improve from 0.83669\nEpoch 50/200\n32/32 [==============================] - 28s 888ms/step - loss: 4.1651 - accuracy: 0.0209 - val_loss: 4.2202 - val_accuracy: 0.0081\n\nEpoch 00050: val_accuracy did not improve from 0.83669\nEpoch 51/200\n32/32 [==============================] - 28s 874ms/step - loss: 4.1506 - accuracy: 0.0279 - val_loss: 4.1595 - val_accuracy: 0.0121\n\nEpoch 00051: val_accuracy did not improve from 0.83669\nEpoch 52/200\n32/32 [==============================] - 28s 881ms/step - loss: 4.1569 - accuracy: 0.0209 - val_loss: 4.1502 - val_accuracy: 0.0202\n\nEpoch 00052: val_accuracy did not improve from 0.83669\nEpoch 53/200\n32/32 [==============================] - 28s 893ms/step - loss: 4.1633 - accuracy: 0.0213 - val_loss: 4.1460 - val_accuracy: 0.0081\n\nEpoch 00053: val_accuracy did not improve from 0.83669\nEpoch 54/200\n32/32 [==============================] - 28s 891ms/step - loss: 4.1645 - accuracy: 0.0177 - val_loss: 4.2077 - val_accuracy: 0.0121\n\nEpoch 00054: val_accuracy did not improve from 0.83669\nEpoch 55/200\n32/32 [==============================] - 29s 894ms/step - loss: 4.1409 - accuracy: 0.0238 - val_loss: 4.2300 - val_accuracy: 0.0121\n\nEpoch 00055: val_accuracy did not improve from 0.83669\nEpoch 56/200\n32/32 [==============================] - 28s 886ms/step - loss: 4.1477 - accuracy: 0.0230 - val_loss: 4.3381 - val_accuracy: 0.0121\n\nEpoch 00056: val_accuracy did not improve from 0.83669\nEpoch 57/200\n32/32 [==============================] - 28s 878ms/step - loss: 4.1648 - accuracy: 0.0178 - val_loss: 5.1927 - val_accuracy: 0.0161\n\nEpoch 00057: val_accuracy did not improve from 0.83669\nEpoch 58/200\n32/32 [==============================] - 28s 869ms/step - loss: 4.1683 - accuracy: 0.0253 - val_loss: 4.5903 - val_accuracy: 0.0081\n\nEpoch 00058: val_accuracy did not improve from 0.83669\nEpoch 59/200\n32/32 [==============================] - 28s 874ms/step - loss: 4.1526 - accuracy: 0.0211 - val_loss: 4.2340 - val_accuracy: 0.0081\n\nEpoch 00059: val_accuracy did not improve from 0.83669\nEpoch 60/200\n32/32 [==============================] - 29s 912ms/step - loss: 4.1616 - accuracy: 0.0182 - val_loss: 4.5367 - val_accuracy: 0.0121\n\nEpoch 00060: val_accuracy did not improve from 0.83669\nEpoch 61/200\n32/32 [==============================] - 28s 893ms/step - loss: 4.1562 - accuracy: 0.0155 - val_loss: 4.2662 - val_accuracy: 0.0161\n\nEpoch 00061: val_accuracy did not improve from 0.83669\nEpoch 62/200\n32/32 [==============================] - 29s 913ms/step - loss: 4.1288 - accuracy: 0.0143 - val_loss: 4.1758 - val_accuracy: 0.0282\n\nEpoch 00062: val_accuracy did not improve from 0.83669\nEpoch 63/200\n32/32 [==============================] - 29s 902ms/step - loss: 4.1370 - accuracy: 0.0179 - val_loss: 4.1726 - val_accuracy: 0.0081\n\nEpoch 00063: val_accuracy did not improve from 0.83669\nEpoch 64/200\n32/32 [==============================] - 28s 893ms/step - loss: 4.1702 - accuracy: 0.0181 - val_loss: 4.1447 - val_accuracy: 0.0081\n\nEpoch 00064: val_accuracy did not improve from 0.83669\nEpoch 65/200\n32/32 [==============================] - 28s 873ms/step - loss: 4.1521 - accuracy: 0.0242 - val_loss: 4.1230 - val_accuracy: 0.0242\n\nEpoch 00065: val_accuracy did not improve from 0.83669\nEpoch 66/200\n32/32 [==============================] - 28s 862ms/step - loss: 4.1464 - accuracy: 0.0179 - val_loss: 4.1484 - val_accuracy: 0.0121\n\nEpoch 00066: val_accuracy did not improve from 0.83669\nEpoch 67/200\n32/32 [==============================] - 28s 861ms/step - loss: 4.1557 - accuracy: 0.0247 - val_loss: 4.1308 - val_accuracy: 0.0363\n\nEpoch 00067: val_accuracy did not improve from 0.83669\nEpoch 68/200\n32/32 [==============================] - 28s 868ms/step - loss: 4.1373 - accuracy: 0.0321 - val_loss: 4.1431 - val_accuracy: 0.0121\n\nEpoch 00068: val_accuracy did not improve from 0.83669\nEpoch 69/200\n32/32 [==============================] - 28s 873ms/step - loss: 4.1267 - accuracy: 0.0152 - val_loss: 4.1327 - val_accuracy: 0.0202\n\nEpoch 00069: val_accuracy did not improve from 0.83669\nEpoch 70/200\n32/32 [==============================] - 28s 873ms/step - loss: 4.1380 - accuracy: 0.0227 - val_loss: 4.1328 - val_accuracy: 0.0323\n\nEpoch 00070: val_accuracy did not improve from 0.83669\nEpoch 71/200\n32/32 [==============================] - 28s 880ms/step - loss: 4.1338 - accuracy: 0.0224 - val_loss: 4.1123 - val_accuracy: 0.0323\n\nEpoch 00071: val_accuracy did not improve from 0.83669\nEpoch 72/200\n32/32 [==============================] - 28s 877ms/step - loss: 4.1422 - accuracy: 0.0292 - val_loss: 4.1301 - val_accuracy: 0.0282\n\nEpoch 00072: val_accuracy did not improve from 0.83669\nEpoch 73/200\n32/32 [==============================] - 28s 865ms/step - loss: 4.1395 - accuracy: 0.0169 - val_loss: 4.1448 - val_accuracy: 0.0202\n\nEpoch 00073: val_accuracy did not improve from 0.83669\nEpoch 74/200\n32/32 [==============================] - 28s 870ms/step - loss: 4.1470 - accuracy: 0.0170 - val_loss: 4.1434 - val_accuracy: 0.0121\n\nEpoch 00074: val_accuracy did not improve from 0.83669\nEpoch 75/200\n32/32 [==============================] - 28s 874ms/step - loss: 4.1517 - accuracy: 0.0148 - val_loss: 4.1413 - val_accuracy: 0.0121\n\nEpoch 00075: val_accuracy did not improve from 0.83669\nEpoch 76/200\n32/32 [==============================] - 28s 881ms/step - loss: 4.1478 - accuracy: 0.0158 - val_loss: 4.1522 - val_accuracy: 0.0202\n\nEpoch 00076: val_accuracy did not improve from 0.83669\nEpoch 77/200\n32/32 [==============================] - 28s 877ms/step - loss: 4.1338 - accuracy: 0.0199 - val_loss: 4.1563 - val_accuracy: 0.0121\n\nEpoch 00077: val_accuracy did not improve from 0.83669\nEpoch 78/200\n32/32 [==============================] - 28s 884ms/step - loss: 4.1362 - accuracy: 0.0161 - val_loss: 4.1339 - val_accuracy: 0.0121\n\nEpoch 00078: val_accuracy did not improve from 0.83669\nEpoch 79/200\n32/32 [==============================] - 28s 887ms/step - loss: 4.1441 - accuracy: 0.0130 - val_loss: 4.1378 - val_accuracy: 0.0242\n\nEpoch 00079: val_accuracy did not improve from 0.83669\nEpoch 80/200\n32/32 [==============================] - 28s 870ms/step - loss: 4.1424 - accuracy: 0.0209 - val_loss: 4.1207 - val_accuracy: 0.0242\n\nEpoch 00080: val_accuracy did not improve from 0.83669\nEpoch 81/200\n32/32 [==============================] - 28s 870ms/step - loss: 4.1543 - accuracy: 0.0194 - val_loss: 4.1237 - val_accuracy: 0.0242\n\nEpoch 00081: val_accuracy did not improve from 0.83669\nEpoch 82/200\n32/32 [==============================] - 28s 870ms/step - loss: 4.1437 - accuracy: 0.0139 - val_loss: 4.1157 - val_accuracy: 0.0161\n\nEpoch 00082: val_accuracy did not improve from 0.83669\nEpoch 83/200\n32/32 [==============================] - 28s 869ms/step - loss: 4.1386 - accuracy: 0.0148 - val_loss: 4.1250 - val_accuracy: 0.0161\n\nEpoch 00083: val_accuracy did not improve from 0.83669\nEpoch 84/200\n32/32 [==============================] - 28s 870ms/step - loss: 4.1547 - accuracy: 0.0315 - val_loss: 4.1196 - val_accuracy: 0.0444\n\nEpoch 00084: val_accuracy did not improve from 0.83669\nEpoch 85/200\n32/32 [==============================] - 28s 869ms/step - loss: 4.1259 - accuracy: 0.0135 - val_loss: 4.1310 - val_accuracy: 0.0282\n\nEpoch 00085: val_accuracy did not improve from 0.83669\nEpoch 86/200\n32/32 [==============================] - 28s 873ms/step - loss: 4.1434 - accuracy: 0.0214 - val_loss: 4.1296 - val_accuracy: 0.0202\n\nEpoch 00086: val_accuracy did not improve from 0.83669\nEpoch 87/200\n32/32 [==============================] - 28s 868ms/step - loss: 4.1374 - accuracy: 0.0181 - val_loss: 10.2680 - val_accuracy: 0.0040\n\nEpoch 00087: val_accuracy did not improve from 0.83669\nEpoch 88/200\n32/32 [==============================] - 28s 878ms/step - loss: 4.1370 - accuracy: 0.0142 - val_loss: 4.5210 - val_accuracy: 0.0202\n\nEpoch 00088: val_accuracy did not improve from 0.83669\nEpoch 89/200\n32/32 [==============================] - 28s 887ms/step - loss: 4.1418 - accuracy: 0.0185 - val_loss: 4.2527 - val_accuracy: 0.0282\n\nEpoch 00089: val_accuracy did not improve from 0.83669\nEpoch 90/200\n32/32 [==============================] - 28s 884ms/step - loss: 4.1516 - accuracy: 0.0179 - val_loss: 4.1980 - val_accuracy: 0.0121\n\nEpoch 00090: val_accuracy did not improve from 0.83669\nEpoch 91/200\n32/32 [==============================] - 29s 903ms/step - loss: 4.1591 - accuracy: 0.0051 - val_loss: 4.1921 - val_accuracy: 0.0121\n\nEpoch 00091: val_accuracy did not improve from 0.83669\nEpoch 92/200\n32/32 [==============================] - 29s 894ms/step - loss: 4.1561 - accuracy: 0.0185 - val_loss: 4.2954 - val_accuracy: 0.0202\n\nEpoch 00092: val_accuracy did not improve from 0.83669\nEpoch 93/200\n32/32 [==============================] - 29s 891ms/step - loss: 4.1485 - accuracy: 0.0162 - val_loss: 4.1686 - val_accuracy: 0.0081\n\nEpoch 00093: val_accuracy did not improve from 0.83669\nEpoch 94/200\n32/32 [==============================] - 28s 893ms/step - loss: 4.1799 - accuracy: 0.0168 - val_loss: 4.1699 - val_accuracy: 0.0202\n\nEpoch 00094: val_accuracy did not improve from 0.83669\nEpoch 95/200\n32/32 [==============================] - 28s 883ms/step - loss: 4.1560 - accuracy: 0.0162 - val_loss: 4.1431 - val_accuracy: 0.0202\n\nEpoch 00095: val_accuracy did not improve from 0.83669\nEpoch 96/200\n32/32 [==============================] - 29s 889ms/step - loss: 4.1445 - accuracy: 0.0095 - val_loss: 4.1247 - val_accuracy: 0.0242\n\nEpoch 00096: val_accuracy did not improve from 0.83669\nEpoch 97/200\n32/32 [==============================] - 28s 883ms/step - loss: 4.1599 - accuracy: 0.0153 - val_loss: 4.1495 - val_accuracy: 0.0202\n\nEpoch 00097: val_accuracy did not improve from 0.83669\nEpoch 98/200\n32/32 [==============================] - 28s 886ms/step - loss: 4.1466 - accuracy: 0.0178 - val_loss: 4.1390 - val_accuracy: 0.0282\n\nEpoch 00098: val_accuracy did not improve from 0.83669\nEpoch 99/200\n32/32 [==============================] - 28s 882ms/step - loss: 4.1503 - accuracy: 0.0210 - val_loss: 4.1687 - val_accuracy: 0.0202\n\nEpoch 00099: val_accuracy did not improve from 0.83669\nEpoch 100/200\n32/32 [==============================] - 28s 886ms/step - loss: 4.1291 - accuracy: 0.0270 - val_loss: 4.2235 - val_accuracy: 0.0121\n\nEpoch 00100: val_accuracy did not improve from 0.83669\nEpoch 101/200\n32/32 [==============================] - 29s 897ms/step - loss: 4.1466 - accuracy: 0.0093 - val_loss: 4.1615 - val_accuracy: 0.0282\n\nEpoch 00101: val_accuracy did not improve from 0.83669\nEpoch 102/200\n32/32 [==============================] - 28s 891ms/step - loss: 4.1534 - accuracy: 0.0305 - val_loss: 4.1442 - val_accuracy: 0.0121\n\nEpoch 00102: val_accuracy did not improve from 0.83669\nEpoch 103/200\n32/32 [==============================] - 28s 892ms/step - loss: 4.1451 - accuracy: 0.0222 - val_loss: 4.1469 - val_accuracy: 0.0161\n\nEpoch 00103: val_accuracy did not improve from 0.83669\nEpoch 104/200\n32/32 [==============================] - 28s 872ms/step - loss: 4.1368 - accuracy: 0.0116 - val_loss: 4.1412 - val_accuracy: 0.0121\n\nEpoch 00104: val_accuracy did not improve from 0.83669\nEpoch 105/200\n32/32 [==============================] - 29s 899ms/step - loss: 4.1428 - accuracy: 0.0193 - val_loss: 4.1390 - val_accuracy: 0.0323\n\nEpoch 00105: val_accuracy did not improve from 0.83669\nEpoch 106/200\n32/32 [==============================] - 29s 898ms/step - loss: 4.1418 - accuracy: 0.0178 - val_loss: 4.1327 - val_accuracy: 0.0081\n\nEpoch 00106: val_accuracy did not improve from 0.83669\nEpoch 107/200\n32/32 [==============================] - 29s 894ms/step - loss: 4.1357 - accuracy: 0.0168 - val_loss: 4.1342 - val_accuracy: 0.0282\n\nEpoch 00107: val_accuracy did not improve from 0.83669\nEpoch 108/200\n32/32 [==============================] - 29s 901ms/step - loss: 4.1351 - accuracy: 0.0165 - val_loss: 4.2381 - val_accuracy: 0.0161\n\nEpoch 00108: val_accuracy did not improve from 0.83669\nEpoch 109/200\n32/32 [==============================] - 28s 893ms/step - loss: 4.1371 - accuracy: 0.0127 - val_loss: 4.1270 - val_accuracy: 0.0121\n\nEpoch 00109: val_accuracy did not improve from 0.83669\nEpoch 110/200\n32/32 [==============================] - 29s 906ms/step - loss: 4.1439 - accuracy: 0.0210 - val_loss: 4.1197 - val_accuracy: 0.0282\n\nEpoch 00110: val_accuracy did not improve from 0.83669\nEpoch 111/200\n32/32 [==============================] - 29s 899ms/step - loss: 4.1366 - accuracy: 0.0217 - val_loss: 4.1214 - val_accuracy: 0.0282\n\nEpoch 00111: val_accuracy did not improve from 0.83669\nEpoch 112/200\n32/32 [==============================] - 28s 887ms/step - loss: 4.1308 - accuracy: 0.0232 - val_loss: 4.1231 - val_accuracy: 0.0161\n\nEpoch 00112: val_accuracy did not improve from 0.83669\nEpoch 113/200\n32/32 [==============================] - 29s 891ms/step - loss: 4.1426 - accuracy: 0.0124 - val_loss: 4.1283 - val_accuracy: 0.0161\n\nEpoch 00113: val_accuracy did not improve from 0.83669\nEpoch 114/200\n32/32 [==============================] - 29s 898ms/step - loss: 4.1402 - accuracy: 0.0203 - val_loss: 4.1299 - val_accuracy: 0.0161\n\nEpoch 00114: val_accuracy did not improve from 0.83669\nEpoch 115/200\n32/32 [==============================] - 29s 905ms/step - loss: 4.1556 - accuracy: 0.0159 - val_loss: 4.1337 - val_accuracy: 0.0161\n\nEpoch 00115: val_accuracy did not improve from 0.83669\nEpoch 116/200\n32/32 [==============================] - 29s 900ms/step - loss: 4.1639 - accuracy: 0.0107 - val_loss: 4.2276 - val_accuracy: 0.0202\n\nEpoch 00116: val_accuracy did not improve from 0.83669\nEpoch 117/200\n32/32 [==============================] - 28s 893ms/step - loss: 4.1302 - accuracy: 0.0181 - val_loss: 4.1629 - val_accuracy: 0.0121\n\nEpoch 00117: val_accuracy did not improve from 0.83669\nEpoch 118/200\n32/32 [==============================] - 28s 889ms/step - loss: 4.1506 - accuracy: 0.0153 - val_loss: 4.1211 - val_accuracy: 0.0202\n\nEpoch 00118: val_accuracy did not improve from 0.83669\nEpoch 119/200\n32/32 [==============================] - 28s 883ms/step - loss: 4.1417 - accuracy: 0.0163 - val_loss: 4.1841 - val_accuracy: 0.0161\n\nEpoch 00119: val_accuracy did not improve from 0.83669\nEpoch 120/200\n32/32 [==============================] - 28s 890ms/step - loss: 4.1468 - accuracy: 0.0127 - val_loss: 4.1482 - val_accuracy: 0.0282\n\nEpoch 00120: val_accuracy did not improve from 0.83669\nEpoch 121/200\n32/32 [==============================] - 28s 882ms/step - loss: 4.1344 - accuracy: 0.0296 - val_loss: 4.1627 - val_accuracy: 0.0081\n\nEpoch 00121: val_accuracy did not improve from 0.83669\nEpoch 122/200\n32/32 [==============================] - 28s 892ms/step - loss: 4.1475 - accuracy: 0.0148 - val_loss: 4.3173 - val_accuracy: 0.0161\n\nEpoch 00122: val_accuracy did not improve from 0.83669\nEpoch 123/200\n32/32 [==============================] - 29s 905ms/step - loss: 4.1541 - accuracy: 0.0200 - val_loss: 4.2355 - val_accuracy: 0.0202\n\nEpoch 00123: val_accuracy did not improve from 0.83669\nEpoch 124/200\n32/32 [==============================] - 29s 899ms/step - loss: 4.1510 - accuracy: 0.0152 - val_loss: 4.1408 - val_accuracy: 0.0202\n\nEpoch 00124: val_accuracy did not improve from 0.83669\nEpoch 125/200\n32/32 [==============================] - 29s 909ms/step - loss: 4.1431 - accuracy: 0.0219 - val_loss: 4.1296 - val_accuracy: 0.0242\n\nEpoch 00125: val_accuracy did not improve from 0.83669\nEpoch 126/200\n32/32 [==============================] - 29s 901ms/step - loss: 4.1247 - accuracy: 0.0202 - val_loss: 4.1272 - val_accuracy: 0.0121\n\nEpoch 00126: val_accuracy did not improve from 0.83669\nEpoch 127/200\n32/32 [==============================] - 28s 890ms/step - loss: 4.1335 - accuracy: 0.0194 - val_loss: 4.1218 - val_accuracy: 0.0161\n\nEpoch 00127: val_accuracy did not improve from 0.83669\nEpoch 128/200\n32/32 [==============================] - 29s 897ms/step - loss: 4.1265 - accuracy: 0.0226 - val_loss: 4.1207 - val_accuracy: 0.0242\n\nEpoch 00128: val_accuracy did not improve from 0.83669\nEpoch 129/200\n32/32 [==============================] - 28s 888ms/step - loss: 4.1220 - accuracy: 0.0253 - val_loss: 4.1580 - val_accuracy: 0.0161\n\nEpoch 00129: val_accuracy did not improve from 0.83669\nEpoch 130/200\n32/32 [==============================] - 28s 888ms/step - loss: 4.1245 - accuracy: 0.0210 - val_loss: 4.1503 - val_accuracy: 0.0161\n\nEpoch 00130: val_accuracy did not improve from 0.83669\nEpoch 131/200\n32/32 [==============================] - 29s 893ms/step - loss: 4.1230 - accuracy: 0.0243 - val_loss: 4.2374 - val_accuracy: 0.0121\n\nEpoch 00131: val_accuracy did not improve from 0.83669\nEpoch 132/200\n32/32 [==============================] - 29s 896ms/step - loss: 4.1384 - accuracy: 0.0260 - val_loss: 5.3052 - val_accuracy: 0.0161\n\nEpoch 00132: val_accuracy did not improve from 0.83669\nEpoch 133/200\n32/32 [==============================] - 29s 904ms/step - loss: 4.1261 - accuracy: 0.0120 - val_loss: 4.2801 - val_accuracy: 0.0161\n\nEpoch 00133: val_accuracy did not improve from 0.83669\nEpoch 134/200\n32/32 [==============================] - 29s 895ms/step - loss: 4.1063 - accuracy: 0.0247 - val_loss: 4.3170 - val_accuracy: 0.0242\n\nEpoch 00134: val_accuracy did not improve from 0.83669\nEpoch 135/200\n32/32 [==============================] - 29s 906ms/step - loss: 4.1184 - accuracy: 0.0259 - val_loss: 4.1548 - val_accuracy: 0.0121\n\nEpoch 00135: val_accuracy did not improve from 0.83669\nEpoch 136/200\n32/32 [==============================] - 29s 905ms/step - loss: 4.1115 - accuracy: 0.0203 - val_loss: 5.2691 - val_accuracy: 0.0161\n\nEpoch 00136: val_accuracy did not improve from 0.83669\nEpoch 137/200\n32/32 [==============================] - 29s 897ms/step - loss: 4.1667 - accuracy: 0.0100 - val_loss: 4.3821 - val_accuracy: 0.0242\n\nEpoch 00137: val_accuracy did not improve from 0.83669\nEpoch 138/200\n32/32 [==============================] - 29s 900ms/step - loss: 4.1512 - accuracy: 0.0151 - val_loss: 4.2314 - val_accuracy: 0.0202\n\nEpoch 00138: val_accuracy did not improve from 0.83669\nEpoch 139/200\n32/32 [==============================] - 28s 888ms/step - loss: 4.1321 - accuracy: 0.0232 - val_loss: 4.1358 - val_accuracy: 0.0242\n\nEpoch 00139: val_accuracy did not improve from 0.83669\nEpoch 140/200\n32/32 [==============================] - 28s 880ms/step - loss: 4.1247 - accuracy: 0.0096 - val_loss: 4.1327 - val_accuracy: 0.0242\n\nEpoch 00140: val_accuracy did not improve from 0.83669\nEpoch 141/200\n32/32 [==============================] - 28s 891ms/step - loss: 4.1151 - accuracy: 0.0285 - val_loss: 4.1268 - val_accuracy: 0.0202\n\nEpoch 00141: val_accuracy did not improve from 0.83669\nEpoch 142/200\n32/32 [==============================] - 28s 889ms/step - loss: 4.0851 - accuracy: 0.0325 - val_loss: 4.8829 - val_accuracy: 0.0081\n\nEpoch 00142: val_accuracy did not improve from 0.83669\nEpoch 143/200\n32/32 [==============================] - 28s 889ms/step - loss: 4.1062 - accuracy: 0.0363 - val_loss: 4.4730 - val_accuracy: 0.0121\n\nEpoch 00143: val_accuracy did not improve from 0.83669\nEpoch 144/200\n32/32 [==============================] - 28s 887ms/step - loss: 4.1434 - accuracy: 0.0298 - val_loss: 4.1833 - val_accuracy: 0.0081\n\nEpoch 00144: val_accuracy did not improve from 0.83669\nEpoch 145/200\n32/32 [==============================] - 29s 899ms/step - loss: 4.0996 - accuracy: 0.0301 - val_loss: 4.5126 - val_accuracy: 0.0121\n\nEpoch 00145: val_accuracy did not improve from 0.83669\nEpoch 146/200\n32/32 [==============================] - 28s 894ms/step - loss: 4.1189 - accuracy: 0.0286 - val_loss: 4.8207 - val_accuracy: 0.0081\n\nEpoch 00146: val_accuracy did not improve from 0.83669\nEpoch 147/200\n32/32 [==============================] - 28s 887ms/step - loss: 4.0676 - accuracy: 0.0333 - val_loss: 7.6169 - val_accuracy: 0.0161\n\nEpoch 00147: val_accuracy did not improve from 0.83669\nEpoch 148/200\n32/32 [==============================] - 28s 885ms/step - loss: 4.1723 - accuracy: 0.0226 - val_loss: 4.4977 - val_accuracy: 0.0161\n\nEpoch 00148: val_accuracy did not improve from 0.83669\nEpoch 149/200\n32/32 [==============================] - 28s 888ms/step - loss: 4.1436 - accuracy: 0.0154 - val_loss: 4.1416 - val_accuracy: 0.0121\n\nEpoch 00149: val_accuracy did not improve from 0.83669\nEpoch 150/200\n32/32 [==============================] - 29s 896ms/step - loss: 4.1356 - accuracy: 0.0196 - val_loss: 4.1669 - val_accuracy: 0.0161\n\nEpoch 00150: val_accuracy did not improve from 0.83669\nEpoch 151/200\n32/32 [==============================] - 29s 902ms/step - loss: 4.1396 - accuracy: 0.0281 - val_loss: 4.6491 - val_accuracy: 0.0202\n\nEpoch 00151: val_accuracy did not improve from 0.83669\nEpoch 152/200\n32/32 [==============================] - 28s 884ms/step - loss: 4.1818 - accuracy: 0.0152 - val_loss: 4.2154 - val_accuracy: 0.0121\n\nEpoch 00152: val_accuracy did not improve from 0.83669\nEpoch 153/200\n32/32 [==============================] - 29s 895ms/step - loss: 4.1677 - accuracy: 0.0218 - val_loss: 4.1455 - val_accuracy: 0.0161\n\nEpoch 00153: val_accuracy did not improve from 0.83669\nEpoch 154/200\n32/32 [==============================] - 28s 893ms/step - loss: 4.1343 - accuracy: 0.0167 - val_loss: 4.1423 - val_accuracy: 0.0202\n\nEpoch 00154: val_accuracy did not improve from 0.83669\nEpoch 155/200\n32/32 [==============================] - 29s 898ms/step - loss: 4.1524 - accuracy: 0.0147 - val_loss: 4.1129 - val_accuracy: 0.0161\n\nEpoch 00155: val_accuracy did not improve from 0.83669\nEpoch 156/200\n32/32 [==============================] - 28s 877ms/step - loss: 4.1320 - accuracy: 0.0192 - val_loss: 4.1406 - val_accuracy: 0.0161\n\nEpoch 00156: val_accuracy did not improve from 0.83669\nEpoch 157/200\n32/32 [==============================] - 28s 876ms/step - loss: 4.1112 - accuracy: 0.0330 - val_loss: 4.1703 - val_accuracy: 0.0121\n\nEpoch 00157: val_accuracy did not improve from 0.83669\nEpoch 158/200\n32/32 [==============================] - 28s 886ms/step - loss: 4.0828 - accuracy: 0.0269 - val_loss: 4.3100 - val_accuracy: 0.0323\n\nEpoch 00158: val_accuracy did not improve from 0.83669\nEpoch 159/200\n32/32 [==============================] - 28s 877ms/step - loss: 4.0753 - accuracy: 0.0369 - val_loss: 4.9423 - val_accuracy: 0.0202\n\nEpoch 00159: val_accuracy did not improve from 0.83669\nEpoch 160/200\n32/32 [==============================] - 28s 881ms/step - loss: 4.0606 - accuracy: 0.0436 - val_loss: 4.1519 - val_accuracy: 0.0161\n\nEpoch 00160: val_accuracy did not improve from 0.83669\nEpoch 161/200\n32/32 [==============================] - 28s 881ms/step - loss: 4.0682 - accuracy: 0.0407 - val_loss: 5.9449 - val_accuracy: 0.0242\n\nEpoch 00161: val_accuracy did not improve from 0.83669\nEpoch 162/200\n32/32 [==============================] - 28s 892ms/step - loss: 4.0466 - accuracy: 0.0345 - val_loss: 4.1372 - val_accuracy: 0.0323\n\nEpoch 00162: val_accuracy did not improve from 0.83669\nEpoch 163/200\n32/32 [==============================] - 28s 862ms/step - loss: 4.0167 - accuracy: 0.0493 - val_loss: 4.0790 - val_accuracy: 0.0242\n\nEpoch 00163: val_accuracy did not improve from 0.83669\nEpoch 164/200\n32/32 [==============================] - 29s 910ms/step - loss: 3.9724 - accuracy: 0.0555 - val_loss: 4.9981 - val_accuracy: 0.0282\n\nEpoch 00164: val_accuracy did not improve from 0.83669\nEpoch 165/200\n32/32 [==============================] - 29s 910ms/step - loss: 3.9822 - accuracy: 0.0336 - val_loss: 4.1466 - val_accuracy: 0.0323\n\nEpoch 00165: val_accuracy did not improve from 0.83669\nEpoch 166/200\n32/32 [==============================] - 29s 907ms/step - loss: 3.9599 - accuracy: 0.0551 - val_loss: 4.0281 - val_accuracy: 0.0565\n\nEpoch 00166: val_accuracy did not improve from 0.83669\nEpoch 167/200\n32/32 [==============================] - 29s 903ms/step - loss: 3.8872 - accuracy: 0.0740 - val_loss: 4.1647 - val_accuracy: 0.0242\n\nEpoch 00167: val_accuracy did not improve from 0.83669\nEpoch 168/200\n32/32 [==============================] - 28s 876ms/step - loss: 3.9137 - accuracy: 0.0493 - val_loss: 4.0491 - val_accuracy: 0.0444\n\nEpoch 00168: val_accuracy did not improve from 0.83669\nEpoch 169/200\n32/32 [==============================] - 28s 888ms/step - loss: 3.8524 - accuracy: 0.0726 - val_loss: 4.0912 - val_accuracy: 0.0282\n\nEpoch 00169: val_accuracy did not improve from 0.83669\nEpoch 170/200\n32/32 [==============================] - 28s 873ms/step - loss: 3.8443 - accuracy: 0.0769 - val_loss: 4.1342 - val_accuracy: 0.0202\n\nEpoch 00170: val_accuracy did not improve from 0.83669\nEpoch 171/200\n32/32 [==============================] - 28s 858ms/step - loss: 3.7428 - accuracy: 0.0788 - val_loss: 4.2189 - val_accuracy: 0.0161\n\nEpoch 00171: val_accuracy did not improve from 0.83669\nEpoch 172/200\n32/32 [==============================] - 28s 886ms/step - loss: 3.6373 - accuracy: 0.1128 - val_loss: 4.2027 - val_accuracy: 0.0202\n\nEpoch 00172: val_accuracy did not improve from 0.83669\nEpoch 173/200\n32/32 [==============================] - 28s 887ms/step - loss: 3.6478 - accuracy: 0.0986 - val_loss: 4.3665 - val_accuracy: 0.0121\n\nEpoch 00173: val_accuracy did not improve from 0.83669\nEpoch 174/200\n32/32 [==============================] - 29s 897ms/step - loss: 3.6101 - accuracy: 0.1118 - val_loss: 4.1900 - val_accuracy: 0.0121\n\nEpoch 00174: val_accuracy did not improve from 0.83669\nEpoch 175/200\n32/32 [==============================] - 28s 892ms/step - loss: 3.5119 - accuracy: 0.1207 - val_loss: 4.0996 - val_accuracy: 0.0363\n\nEpoch 00175: val_accuracy did not improve from 0.83669\nEpoch 176/200\n32/32 [==============================] - 29s 905ms/step - loss: 3.4350 - accuracy: 0.1339 - val_loss: 4.1654 - val_accuracy: 0.0282\n\nEpoch 00176: val_accuracy did not improve from 0.83669\nEpoch 177/200\n32/32 [==============================] - 28s 890ms/step - loss: 3.3964 - accuracy: 0.1680 - val_loss: 4.0879 - val_accuracy: 0.0605\n\nEpoch 00177: val_accuracy did not improve from 0.83669\nEpoch 178/200\n32/32 [==============================] - 28s 870ms/step - loss: 3.2257 - accuracy: 0.1970 - val_loss: 3.8830 - val_accuracy: 0.0927\n\nEpoch 00178: val_accuracy did not improve from 0.83669\nEpoch 179/200\n32/32 [==============================] - 28s 883ms/step - loss: 3.1827 - accuracy: 0.2325 - val_loss: 4.0144 - val_accuracy: 0.0484\n\nEpoch 00179: val_accuracy did not improve from 0.83669\nEpoch 180/200\n32/32 [==============================] - 28s 885ms/step - loss: 3.1113 - accuracy: 0.2461 - val_loss: 4.0206 - val_accuracy: 0.0484\n\nEpoch 00180: val_accuracy did not improve from 0.83669\nEpoch 181/200\n32/32 [==============================] - 29s 894ms/step - loss: 2.9784 - accuracy: 0.2398 - val_loss: 4.0906 - val_accuracy: 0.0605\n\nEpoch 00181: val_accuracy did not improve from 0.83669\nEpoch 182/200\n32/32 [==============================] - 28s 886ms/step - loss: 2.9308 - accuracy: 0.2760 - val_loss: 3.7629 - val_accuracy: 0.1129\n\nEpoch 00182: val_accuracy did not improve from 0.83669\nEpoch 183/200\n32/32 [==============================] - 29s 898ms/step - loss: 2.8712 - accuracy: 0.3299 - val_loss: 3.4955 - val_accuracy: 0.2218\n\nEpoch 00183: val_accuracy did not improve from 0.83669\nEpoch 184/200\n32/32 [==============================] - 29s 896ms/step - loss: 2.6461 - accuracy: 0.4040 - val_loss: 3.3883 - val_accuracy: 0.2258\n\nEpoch 00184: val_accuracy did not improve from 0.83669\nEpoch 185/200\n32/32 [==============================] - 28s 879ms/step - loss: 2.5596 - accuracy: 0.4107 - val_loss: 3.3745 - val_accuracy: 0.2177\n\nEpoch 00185: val_accuracy did not improve from 0.83669\nEpoch 186/200\n32/32 [==============================] - 28s 873ms/step - loss: 2.3973 - accuracy: 0.4498 - val_loss: 3.0801 - val_accuracy: 0.3347\n\nEpoch 00186: val_accuracy did not improve from 0.83669\nEpoch 187/200\n32/32 [==============================] - 29s 895ms/step - loss: 2.3403 - accuracy: 0.5091 - val_loss: 3.2077 - val_accuracy: 0.2258\n\nEpoch 00187: val_accuracy did not improve from 0.83669\nEpoch 188/200\n32/32 [==============================] - 28s 889ms/step - loss: 2.2860 - accuracy: 0.4814 - val_loss: 3.1477 - val_accuracy: 0.2137\n\nEpoch 00188: val_accuracy did not improve from 0.83669\nEpoch 189/200\n32/32 [==============================] - 28s 884ms/step - loss: 2.1492 - accuracy: 0.5368 - val_loss: 2.7917 - val_accuracy: 0.4516\n\nEpoch 00189: val_accuracy did not improve from 0.83669\nEpoch 190/200\n32/32 [==============================] - 28s 892ms/step - loss: 1.9261 - accuracy: 0.6097 - val_loss: 2.6080 - val_accuracy: 0.5000\n\nEpoch 00190: val_accuracy did not improve from 0.83669\nEpoch 191/200\n32/32 [==============================] - 29s 909ms/step - loss: 1.9361 - accuracy: 0.5908 - val_loss: 2.6725 - val_accuracy: 0.4597\n\nEpoch 00191: val_accuracy did not improve from 0.83669\nEpoch 192/200\n32/32 [==============================] - 28s 892ms/step - loss: 1.7804 - accuracy: 0.6412 - val_loss: 2.2617 - val_accuracy: 0.5565\n\nEpoch 00192: val_accuracy did not improve from 0.83669\nEpoch 193/200\n32/32 [==============================] - 29s 896ms/step - loss: 1.6685 - accuracy: 0.7299 - val_loss: 2.3495 - val_accuracy: 0.5444\n\nEpoch 00193: val_accuracy did not improve from 0.83669\nEpoch 194/200\n32/32 [==============================] - 28s 865ms/step - loss: 1.6094 - accuracy: 0.6921 - val_loss: 2.0887 - val_accuracy: 0.6048\n\nEpoch 00194: val_accuracy did not improve from 0.83669\nEpoch 195/200\n32/32 [==============================] - 28s 889ms/step - loss: 1.4847 - accuracy: 0.7529 - val_loss: 2.0968 - val_accuracy: 0.5847\n\nEpoch 00195: val_accuracy did not improve from 0.83669\nEpoch 196/200\n32/32 [==============================] - 29s 897ms/step - loss: 1.4523 - accuracy: 0.7281 - val_loss: 1.9768 - val_accuracy: 0.6371\n\nEpoch 00196: val_accuracy did not improve from 0.83669\nEpoch 197/200\n32/32 [==============================] - 29s 901ms/step - loss: 1.3595 - accuracy: 0.7670 - val_loss: 1.8499 - val_accuracy: 0.5968\n\nEpoch 00197: val_accuracy did not improve from 0.83669\nEpoch 198/200\n32/32 [==============================] - 29s 903ms/step - loss: 1.2808 - accuracy: 0.7862 - val_loss: 1.8151 - val_accuracy: 0.6331\n\nEpoch 00198: val_accuracy did not improve from 0.83669\nEpoch 199/200\n32/32 [==============================] - 28s 889ms/step - loss: 1.1914 - accuracy: 0.8065 - val_loss: 1.5448 - val_accuracy: 0.6694\n\nEpoch 00199: val_accuracy did not improve from 0.83669\nEpoch 200/200\n32/32 [==============================] - 29s 898ms/step - loss: 1.0838 - accuracy: 0.8330 - val_loss: 1.6386 - val_accuracy: 0.6976\n\nEpoch 00200: val_accuracy did not improve from 0.83669\n","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f1d30367590>"},"metadata":{}}]}]}