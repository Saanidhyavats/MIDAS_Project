{"metadata":{"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TASK-2**","metadata":{}},{"cell_type":"markdown","source":"# Moving to the directory where data is stored","metadata":{}},{"cell_type":"code","source":"cd ../input/task-2","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/task-2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Importing the required libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow.keras\nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense,Conv2D,Flatten,Dropout,MaxPool2D,AvgPool2D,BatchNormalization,Activation,Input\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential,Model\nfrom tensorflow.keras.applications import InceptionV3","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Variable learning rate with lr=0.001, deacy= 0.001/200, momnetum=0.9","metadata":{}},{"cell_type":"code","source":"lr_schedule = tensorflow.keras.optimizers.SGD(\n    lr=0.001,\n    decay= 0.001/200,\n    momentum=0.9)","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Data flow pipeline with addition of some noise (brightness and zoom)","metadata":{}},{"cell_type":"code","source":"datagen= ImageDataGenerator(\nzoom_range=0.15,\nbrightness_range = [0.3,1.4],\nvalidation_split=0.20)\ntrain_it=datagen.flow_from_directory('train_task2',class_mode='categorical',batch_size=20,target_size=(28,28),shuffle=True,color_mode='grayscale',subset='training')\ntest_it= datagen.flow_from_directory('train_task2',class_mode='categorical',batch_size=20,target_size=(28,28),shuffle=True,color_mode='grayscale',subset='validation')","metadata":{"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Found 320 images belonging to 10 classes.\nFound 80 images belonging to 10 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model architecture with structure inspired from VGG with addition of dropout and batch normalization layers to avoid overfitting and reduce the training time.","metadata":{}},{"cell_type":"code","source":"model=Sequential()\nmodel.add(Conv2D(32, (5, 5), padding=\"same\",input_shape=(28,28,1)))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(256, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(50))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\nmodel.add(Dense(10))\nmodel.add(Activation(\"softmax\"))","metadata":{"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Compiling the model","metadata":{}},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer= lr_schedule)\n","metadata":{"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Saving the weights in the file with max val accuracy ","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\nfilepath='../../working/mymodel2.h5'\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\n","metadata":{"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Training the model","metadata":{}},{"cell_type":"code","source":"model.fit(train_it,steps_per_epoch=int(320/20),epochs=50,validation_data=test_it,validation_steps=int(80/20),callbacks=callbacks_list)\n","metadata":{"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Epoch 1/50\n16/16 [==============================] - 8s 527ms/step - loss: 0.0734 - accuracy: 0.9906 - val_loss: 0.5086 - val_accuracy: 0.8375\n\nEpoch 00001: val_accuracy did not improve from 0.88750\nEpoch 2/50\n16/16 [==============================] - 8s 505ms/step - loss: 0.0899 - accuracy: 0.9719 - val_loss: 0.4731 - val_accuracy: 0.8625\n\nEpoch 00002: val_accuracy did not improve from 0.88750\nEpoch 3/50\n16/16 [==============================] - 8s 510ms/step - loss: 0.0858 - accuracy: 0.9844 - val_loss: 0.7216 - val_accuracy: 0.7875\n\nEpoch 00003: val_accuracy did not improve from 0.88750\nEpoch 4/50\n16/16 [==============================] - 8s 501ms/step - loss: 0.1421 - accuracy: 0.9594 - val_loss: 0.5044 - val_accuracy: 0.8125\n\nEpoch 00004: val_accuracy did not improve from 0.88750\nEpoch 5/50\n16/16 [==============================] - 8s 504ms/step - loss: 0.0805 - accuracy: 0.9844 - val_loss: 0.5555 - val_accuracy: 0.8000\n\nEpoch 00005: val_accuracy did not improve from 0.88750\nEpoch 6/50\n16/16 [==============================] - 8s 506ms/step - loss: 0.0726 - accuracy: 0.9844 - val_loss: 0.4794 - val_accuracy: 0.8500\n\nEpoch 00006: val_accuracy did not improve from 0.88750\nEpoch 7/50\n16/16 [==============================] - 8s 509ms/step - loss: 0.0933 - accuracy: 0.9844 - val_loss: 0.6573 - val_accuracy: 0.8625\n\nEpoch 00007: val_accuracy did not improve from 0.88750\nEpoch 8/50\n16/16 [==============================] - 8s 502ms/step - loss: 0.1250 - accuracy: 0.9594 - val_loss: 0.5787 - val_accuracy: 0.8375\n\nEpoch 00008: val_accuracy did not improve from 0.88750\nEpoch 9/50\n16/16 [==============================] - 8s 504ms/step - loss: 0.0866 - accuracy: 0.9750 - val_loss: 0.6247 - val_accuracy: 0.8250\n\nEpoch 00009: val_accuracy did not improve from 0.88750\nEpoch 10/50\n16/16 [==============================] - 8s 507ms/step - loss: 0.0839 - accuracy: 0.9906 - val_loss: 0.4947 - val_accuracy: 0.8500\n\nEpoch 00010: val_accuracy did not improve from 0.88750\nEpoch 11/50\n16/16 [==============================] - 8s 509ms/step - loss: 0.0758 - accuracy: 0.9844 - val_loss: 0.6299 - val_accuracy: 0.8500\n\nEpoch 00011: val_accuracy did not improve from 0.88750\nEpoch 12/50\n16/16 [==============================] - 8s 497ms/step - loss: 0.0793 - accuracy: 0.9906 - val_loss: 0.7271 - val_accuracy: 0.8000\n\nEpoch 00012: val_accuracy did not improve from 0.88750\nEpoch 13/50\n16/16 [==============================] - 8s 503ms/step - loss: 0.0934 - accuracy: 0.9844 - val_loss: 0.5583 - val_accuracy: 0.8000\n\nEpoch 00013: val_accuracy did not improve from 0.88750\nEpoch 14/50\n16/16 [==============================] - 8s 505ms/step - loss: 0.0783 - accuracy: 0.9844 - val_loss: 0.4893 - val_accuracy: 0.8500\n\nEpoch 00014: val_accuracy did not improve from 0.88750\nEpoch 15/50\n16/16 [==============================] - 8s 507ms/step - loss: 0.0830 - accuracy: 0.9781 - val_loss: 0.6882 - val_accuracy: 0.7875\n\nEpoch 00015: val_accuracy did not improve from 0.88750\nEpoch 16/50\n16/16 [==============================] - 8s 500ms/step - loss: 0.0809 - accuracy: 0.9844 - val_loss: 0.5324 - val_accuracy: 0.8750\n\nEpoch 00016: val_accuracy did not improve from 0.88750\nEpoch 17/50\n16/16 [==============================] - 8s 505ms/step - loss: 0.0936 - accuracy: 0.9719 - val_loss: 0.5855 - val_accuracy: 0.8625\n\nEpoch 00017: val_accuracy did not improve from 0.88750\nEpoch 18/50\n16/16 [==============================] - 8s 501ms/step - loss: 0.0854 - accuracy: 0.9781 - val_loss: 0.5270 - val_accuracy: 0.8500\n\nEpoch 00018: val_accuracy did not improve from 0.88750\nEpoch 19/50\n16/16 [==============================] - 8s 507ms/step - loss: 0.0836 - accuracy: 0.9844 - val_loss: 0.7378 - val_accuracy: 0.8250\n\nEpoch 00019: val_accuracy did not improve from 0.88750\nEpoch 20/50\n16/16 [==============================] - 8s 501ms/step - loss: 0.1018 - accuracy: 0.9750 - val_loss: 0.5284 - val_accuracy: 0.8375\n\nEpoch 00020: val_accuracy did not improve from 0.88750\nEpoch 21/50\n16/16 [==============================] - 8s 501ms/step - loss: 0.0598 - accuracy: 0.9969 - val_loss: 0.5845 - val_accuracy: 0.8250\n\nEpoch 00021: val_accuracy did not improve from 0.88750\nEpoch 22/50\n16/16 [==============================] - 8s 504ms/step - loss: 0.0656 - accuracy: 0.9812 - val_loss: 0.7577 - val_accuracy: 0.7750\n\nEpoch 00022: val_accuracy did not improve from 0.88750\nEpoch 23/50\n16/16 [==============================] - 8s 508ms/step - loss: 0.1070 - accuracy: 0.9688 - val_loss: 0.6857 - val_accuracy: 0.8375\n\nEpoch 00023: val_accuracy did not improve from 0.88750\nEpoch 24/50\n16/16 [==============================] - 8s 503ms/step - loss: 0.0709 - accuracy: 0.9844 - val_loss: 0.4832 - val_accuracy: 0.8875\n\nEpoch 00024: val_accuracy did not improve from 0.88750\nEpoch 25/50\n16/16 [==============================] - 8s 508ms/step - loss: 0.0870 - accuracy: 0.9844 - val_loss: 0.5370 - val_accuracy: 0.8625\n\nEpoch 00025: val_accuracy did not improve from 0.88750\nEpoch 26/50\n16/16 [==============================] - 8s 518ms/step - loss: 0.0604 - accuracy: 0.9844 - val_loss: 0.5864 - val_accuracy: 0.8000\n\nEpoch 00026: val_accuracy did not improve from 0.88750\nEpoch 27/50\n16/16 [==============================] - 8s 504ms/step - loss: 0.0837 - accuracy: 0.9875 - val_loss: 0.6088 - val_accuracy: 0.8375\n\nEpoch 00027: val_accuracy did not improve from 0.88750\nEpoch 28/50\n16/16 [==============================] - 8s 508ms/step - loss: 0.1024 - accuracy: 0.9719 - val_loss: 0.6463 - val_accuracy: 0.8000\n\nEpoch 00028: val_accuracy did not improve from 0.88750\nEpoch 29/50\n16/16 [==============================] - 8s 506ms/step - loss: 0.0766 - accuracy: 0.9844 - val_loss: 0.6676 - val_accuracy: 0.7875\n\nEpoch 00029: val_accuracy did not improve from 0.88750\nEpoch 30/50\n16/16 [==============================] - 8s 499ms/step - loss: 0.0643 - accuracy: 0.9875 - val_loss: 0.6277 - val_accuracy: 0.8250\n\nEpoch 00030: val_accuracy did not improve from 0.88750\nEpoch 31/50\n16/16 [==============================] - 8s 511ms/step - loss: 0.0912 - accuracy: 0.9844 - val_loss: 0.5478 - val_accuracy: 0.8000\n\nEpoch 00031: val_accuracy did not improve from 0.88750\nEpoch 32/50\n16/16 [==============================] - 8s 501ms/step - loss: 0.0797 - accuracy: 0.9844 - val_loss: 0.4915 - val_accuracy: 0.8375\n\nEpoch 00032: val_accuracy did not improve from 0.88750\nEpoch 33/50\n16/16 [==============================] - 8s 505ms/step - loss: 0.0717 - accuracy: 0.9812 - val_loss: 0.5284 - val_accuracy: 0.8625\n\nEpoch 00033: val_accuracy did not improve from 0.88750\nEpoch 34/50\n16/16 [==============================] - 8s 501ms/step - loss: 0.0692 - accuracy: 0.9875 - val_loss: 0.5228 - val_accuracy: 0.9000\n\nEpoch 00034: val_accuracy improved from 0.88750 to 0.90000, saving model to ../../working/mymodel2.h5\nEpoch 35/50\n16/16 [==============================] - 8s 503ms/step - loss: 0.0693 - accuracy: 0.9844 - val_loss: 0.5880 - val_accuracy: 0.8250\n\nEpoch 00035: val_accuracy did not improve from 0.90000\nEpoch 36/50\n16/16 [==============================] - 8s 505ms/step - loss: 0.0684 - accuracy: 0.9906 - val_loss: 0.5457 - val_accuracy: 0.8125\n\nEpoch 00036: val_accuracy did not improve from 0.90000\nEpoch 37/50\n16/16 [==============================] - 8s 502ms/step - loss: 0.0623 - accuracy: 0.9844 - val_loss: 0.8200 - val_accuracy: 0.8000\n\nEpoch 00037: val_accuracy did not improve from 0.90000\nEpoch 38/50\n16/16 [==============================] - 8s 502ms/step - loss: 0.0754 - accuracy: 0.9812 - val_loss: 0.4219 - val_accuracy: 0.9000\n\nEpoch 00038: val_accuracy did not improve from 0.90000\nEpoch 39/50\n16/16 [==============================] - 8s 500ms/step - loss: 0.0514 - accuracy: 0.9906 - val_loss: 0.6551 - val_accuracy: 0.8125\n\nEpoch 00039: val_accuracy did not improve from 0.90000\nEpoch 40/50\n16/16 [==============================] - 8s 504ms/step - loss: 0.0597 - accuracy: 0.9937 - val_loss: 0.4594 - val_accuracy: 0.8375\n\nEpoch 00040: val_accuracy did not improve from 0.90000\nEpoch 41/50\n16/16 [==============================] - 8s 501ms/step - loss: 0.0396 - accuracy: 0.9969 - val_loss: 0.5671 - val_accuracy: 0.8250\n\nEpoch 00041: val_accuracy did not improve from 0.90000\nEpoch 42/50\n16/16 [==============================] - 8s 503ms/step - loss: 0.0744 - accuracy: 0.9875 - val_loss: 0.5452 - val_accuracy: 0.8500\n\nEpoch 00042: val_accuracy did not improve from 0.90000\nEpoch 43/50\n16/16 [==============================] - 8s 500ms/step - loss: 0.0443 - accuracy: 0.9937 - val_loss: 0.4384 - val_accuracy: 0.8875\n\nEpoch 00043: val_accuracy did not improve from 0.90000\nEpoch 44/50\n16/16 [==============================] - 8s 501ms/step - loss: 0.0660 - accuracy: 0.9906 - val_loss: 0.5160 - val_accuracy: 0.8625\n\nEpoch 00044: val_accuracy did not improve from 0.90000\nEpoch 45/50\n16/16 [==============================] - 8s 496ms/step - loss: 0.0654 - accuracy: 0.9844 - val_loss: 0.7177 - val_accuracy: 0.8000\n\nEpoch 00045: val_accuracy did not improve from 0.90000\nEpoch 46/50\n16/16 [==============================] - 8s 504ms/step - loss: 0.0605 - accuracy: 0.9875 - val_loss: 0.5619 - val_accuracy: 0.8125\n\nEpoch 00046: val_accuracy did not improve from 0.90000\nEpoch 47/50\n16/16 [==============================] - 8s 502ms/step - loss: 0.0586 - accuracy: 0.9844 - val_loss: 0.4872 - val_accuracy: 0.8625\n\nEpoch 00047: val_accuracy did not improve from 0.90000\nEpoch 48/50\n16/16 [==============================] - 8s 501ms/step - loss: 0.0755 - accuracy: 0.9781 - val_loss: 0.3767 - val_accuracy: 0.8875\n\nEpoch 00048: val_accuracy did not improve from 0.90000\nEpoch 49/50\n16/16 [==============================] - 8s 500ms/step - loss: 0.0680 - accuracy: 0.9844 - val_loss: 0.4906 - val_accuracy: 0.8625\n\nEpoch 00049: val_accuracy did not improve from 0.90000\nEpoch 50/50\n16/16 [==============================] - 8s 509ms/step - loss: 0.0568 - accuracy: 0.9906 - val_loss: 0.6034 - val_accuracy: 0.8125\n\nEpoch 00050: val_accuracy did not improve from 0.90000\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7ff05c1e8bd0>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Max val accuracy reached to 90%","metadata":{}},{"cell_type":"markdown","source":"# MNIST Data","metadata":{}},{"cell_type":"code","source":"from keras.datasets import mnist\n(train_X, train_y), (test_X, test_y) = mnist.load_data()\nimport tensorflow as tf\ntrain_X=train_X.reshape(60000,28,28,1)\ntest_X= test_X.reshape(10000,28,28,1)","metadata":{"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11493376/11490434 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Applying onehotencoding in the output data","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\ntest_y=test_y.reshape(10000,1)\n# creating instance of one-hot-encoder\nenc = OneHotEncoder(handle_unknown='ignore')\n# passing bridge-types-cat column (label encoded values of bridge_types)\ntest_y = pd.DataFrame(enc.fit_transform(test_y).toarray())\n# merge with main df bridge_df on key values\n\n#bridge_df = bridge_df.join(enc_df)","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\ntrain_y=train_y.reshape(60000,1)\n# creating instance of one-hot-encoder\nenc = OneHotEncoder(handle_unknown='ignore')\n# passing bridge-types-cat column (label encoded values of bridge_types)\ntrain_y = pd.DataFrame(enc.fit_transform(train_y).toarray())\n","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Same model with random initialized weights","metadata":{}},{"cell_type":"code","source":"model1=Sequential()\nmodel1.add(Conv2D(32, (5, 5), padding=\"same\",input_shape=(28,28,1)))\nmodel1.add(Activation(\"relu\"))\nmodel1.add(BatchNormalization())\nmodel1.add(Conv2D(32, (3, 3), padding=\"same\"))\nmodel1.add(BatchNormalization())\nmodel1.add(MaxPool2D(pool_size=(2, 2)))\nmodel1.add(Dropout(0.2))\nmodel1.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel1.add(Activation(\"relu\"))\nmodel1.add(BatchNormalization())\nmodel1.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel1.add(Activation(\"relu\"))\nmodel1.add(BatchNormalization())\nmodel1.add(MaxPool2D(pool_size=(2, 2)))\nmodel1.add(Dropout(0.2))\nmodel1.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel1.add(Activation(\"relu\"))\nmodel1.add(BatchNormalization())\nmodel1.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel1.add(Activation(\"relu\"))\nmodel1.add(BatchNormalization())\nmodel1.add(MaxPool2D(pool_size=(2, 2)))\nmodel1.add(Dropout(0.2))\nmodel1.add(Conv2D(256, (3, 3), padding=\"same\"))\nmodel1.add(Activation(\"relu\"))\nmodel1.add(BatchNormalization())\nmodel1.add(Conv2D(256, (3, 3), padding=\"same\"))\nmodel1.add(Activation(\"relu\"))\nmodel1.add(BatchNormalization())\nmodel1.add(MaxPool2D(pool_size=(2, 2)))\nmodel1.add(Dropout(0.2))\nmodel1.add(Flatten())\nmodel1.add(Dense(50))\nmodel1.add(Activation(\"relu\"))\nmodel1.add(BatchNormalization())\nmodel1.add(Dropout(0.3))\nmodel1.add(Dense(10))\nmodel1.add(Activation(\"softmax\"))","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Compiling and training the model","metadata":{}},{"cell_type":"code","source":"model1.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer= lr_schedule)\nmodel1.fit(train_X,train_y,batch_size=50,epochs=50,validation_data=(test_X,test_y),callbacks=callbacks_list)","metadata":{"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/50\n1200/1200 [==============================] - 318s 264ms/step - loss: 0.7408 - accuracy: 0.7812 - val_loss: 0.0531 - val_accuracy: 0.9827\nEpoch 2/50\n1200/1200 [==============================] - 317s 264ms/step - loss: 0.1190 - accuracy: 0.9676 - val_loss: 0.0391 - val_accuracy: 0.9869\nEpoch 3/50\n1200/1200 [==============================] - 315s 263ms/step - loss: 0.0804 - accuracy: 0.9781 - val_loss: 0.0318 - val_accuracy: 0.9893\nEpoch 4/50\n1200/1200 [==============================] - 315s 262ms/step - loss: 0.0672 - accuracy: 0.9815 - val_loss: 0.0292 - val_accuracy: 0.9904\nEpoch 5/50\n1200/1200 [==============================] - 314s 261ms/step - loss: 0.0552 - accuracy: 0.9852 - val_loss: 0.0256 - val_accuracy: 0.9905\nEpoch 6/50\n1200/1200 [==============================] - 314s 262ms/step - loss: 0.0486 - accuracy: 0.9866 - val_loss: 0.0229 - val_accuracy: 0.9926\nEpoch 7/50\n1200/1200 [==============================] - 313s 261ms/step - loss: 0.0439 - accuracy: 0.9874 - val_loss: 0.0239 - val_accuracy: 0.9922\nEpoch 8/50\n1200/1200 [==============================] - 314s 262ms/step - loss: 0.0400 - accuracy: 0.9890 - val_loss: 0.0215 - val_accuracy: 0.9928\nEpoch 9/50\n1200/1200 [==============================] - 315s 263ms/step - loss: 0.0347 - accuracy: 0.9905 - val_loss: 0.0201 - val_accuracy: 0.9933\nEpoch 10/50\n1200/1200 [==============================] - 314s 262ms/step - loss: 0.0300 - accuracy: 0.9918 - val_loss: 0.0202 - val_accuracy: 0.9939\nEpoch 11/50\n1200/1200 [==============================] - 313s 261ms/step - loss: 0.0309 - accuracy: 0.9910 - val_loss: 0.0194 - val_accuracy: 0.9938\nEpoch 12/50\n1200/1200 [==============================] - 313s 260ms/step - loss: 0.0278 - accuracy: 0.9923 - val_loss: 0.0202 - val_accuracy: 0.9939\nEpoch 13/50\n1200/1200 [==============================] - 314s 261ms/step - loss: 0.0290 - accuracy: 0.9920 - val_loss: 0.0196 - val_accuracy: 0.9950\nEpoch 14/50\n1200/1200 [==============================] - 313s 261ms/step - loss: 0.0244 - accuracy: 0.9929 - val_loss: 0.0195 - val_accuracy: 0.9947\nEpoch 15/50\n1200/1200 [==============================] - 315s 262ms/step - loss: 0.0252 - accuracy: 0.9927 - val_loss: 0.0197 - val_accuracy: 0.9943\nEpoch 16/50\n1200/1200 [==============================] - 313s 261ms/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 0.0195 - val_accuracy: 0.9947\nEpoch 17/50\n1200/1200 [==============================] - 314s 261ms/step - loss: 0.0187 - accuracy: 0.9945 - val_loss: 0.0180 - val_accuracy: 0.9950\nEpoch 18/50\n1200/1200 [==============================] - 314s 261ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 0.0182 - val_accuracy: 0.9947\nEpoch 19/50\n1200/1200 [==============================] - 314s 261ms/step - loss: 0.0181 - accuracy: 0.9949 - val_loss: 0.0193 - val_accuracy: 0.9951\nEpoch 20/50\n1200/1200 [==============================] - 315s 263ms/step - loss: 0.0198 - accuracy: 0.9949 - val_loss: 0.0168 - val_accuracy: 0.9952\nEpoch 21/50\n1200/1200 [==============================] - 314s 262ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.0183 - val_accuracy: 0.9948\nEpoch 22/50\n1200/1200 [==============================] - 314s 262ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.0177 - val_accuracy: 0.9949\nEpoch 23/50\n1200/1200 [==============================] - 314s 262ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.0196 - val_accuracy: 0.9946\nEpoch 24/50\n1200/1200 [==============================] - 314s 262ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.0178 - val_accuracy: 0.9951\nEpoch 25/50\n1200/1200 [==============================] - 314s 262ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.0187 - val_accuracy: 0.9949\nEpoch 26/50\n1200/1200 [==============================] - 314s 262ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.0190 - val_accuracy: 0.9943\nEpoch 27/50\n1200/1200 [==============================] - 314s 262ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 0.0174 - val_accuracy: 0.9951\nEpoch 28/50\n1200/1200 [==============================] - 314s 262ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.0164 - val_accuracy: 0.9953\nEpoch 29/50\n1200/1200 [==============================] - 315s 262ms/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.0185 - val_accuracy: 0.9946\nEpoch 30/50\n1200/1200 [==============================] - 315s 262ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 0.0193 - val_accuracy: 0.9945\nEpoch 31/50\n1200/1200 [==============================] - 316s 263ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.0191 - val_accuracy: 0.9951\nEpoch 32/50\n1200/1200 [==============================] - 316s 264ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.0188 - val_accuracy: 0.9951\nEpoch 33/50\n1200/1200 [==============================] - 316s 263ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.0174 - val_accuracy: 0.9952\nEpoch 34/50\n1200/1200 [==============================] - 318s 265ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.0193 - val_accuracy: 0.9952\nEpoch 35/50\n1200/1200 [==============================] - 317s 264ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0205 - val_accuracy: 0.9951\nEpoch 36/50\n1200/1200 [==============================] - 315s 262ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.0184 - val_accuracy: 0.9944\nEpoch 37/50\n1200/1200 [==============================] - 314s 262ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.0186 - val_accuracy: 0.9946\nEpoch 38/50\n1200/1200 [==============================] - 315s 263ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.0204 - val_accuracy: 0.9947\nEpoch 39/50\n1200/1200 [==============================] - 315s 262ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.0218 - val_accuracy: 0.9941\nEpoch 40/50\n1200/1200 [==============================] - 314s 262ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.0205 - val_accuracy: 0.9948\nEpoch 41/50\n1200/1200 [==============================] - 315s 263ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.0194 - val_accuracy: 0.9946\nEpoch 42/50\n1200/1200 [==============================] - 317s 264ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.0205 - val_accuracy: 0.9947\nEpoch 43/50\n1200/1200 [==============================] - 318s 265ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.0192 - val_accuracy: 0.9956\nEpoch 44/50\n1200/1200 [==============================] - 319s 266ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.0193 - val_accuracy: 0.9945\nEpoch 45/50\n1200/1200 [==============================] - 319s 266ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.0207 - val_accuracy: 0.9949\nEpoch 46/50\n1200/1200 [==============================] - 317s 264ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0187 - val_accuracy: 0.9951\nEpoch 47/50\n1200/1200 [==============================] - 316s 263ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0200 - val_accuracy: 0.9951\nEpoch 48/50\n1200/1200 [==============================] - 316s 263ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0217 - val_accuracy: 0.9949\nEpoch 49/50\n1200/1200 [==============================] - 316s 263ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.0202 - val_accuracy: 0.9951\nEpoch 50/50\n1200/1200 [==============================] - 317s 264ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0209 - val_accuracy: 0.9950\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7ff06074be90>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Compiling and training the same model with weights pretrained from dataset given in task-1 (The first trained model of this notebook is used below). Since the val accuracy reached above 99%, I stopped the training after 15 epochs due to which keyboard interrupt error is shown below(due to time limitations of the notebook session on kaggle)","metadata":{}},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer= lr_schedule)\nmodel.fit(train_X,train_y,batch_size=50,epochs=50,validation_data=(test_X,test_y))","metadata":{"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/50\n1200/1200 [==============================] - 317s 263ms/step - loss: 0.6923 - accuracy: 0.8046 - val_loss: 0.0628 - val_accuracy: 0.9796\nEpoch 2/50\n1200/1200 [==============================] - 316s 263ms/step - loss: 0.1374 - accuracy: 0.9640 - val_loss: 0.0445 - val_accuracy: 0.9852\nEpoch 3/50\n1200/1200 [==============================] - 315s 263ms/step - loss: 0.0990 - accuracy: 0.9740 - val_loss: 0.0343 - val_accuracy: 0.9885\nEpoch 4/50\n1200/1200 [==============================] - 316s 263ms/step - loss: 0.0774 - accuracy: 0.9792 - val_loss: 0.0289 - val_accuracy: 0.9901\nEpoch 5/50\n1200/1200 [==============================] - 316s 264ms/step - loss: 0.0643 - accuracy: 0.9832 - val_loss: 0.0285 - val_accuracy: 0.9904\nEpoch 6/50\n1200/1200 [==============================] - 317s 264ms/step - loss: 0.0584 - accuracy: 0.9840 - val_loss: 0.0243 - val_accuracy: 0.9906\nEpoch 7/50\n1200/1200 [==============================] - 317s 264ms/step - loss: 0.0531 - accuracy: 0.9857 - val_loss: 0.0232 - val_accuracy: 0.9919\nEpoch 8/50\n1200/1200 [==============================] - 316s 263ms/step - loss: 0.0493 - accuracy: 0.9861 - val_loss: 0.0211 - val_accuracy: 0.9926\nEpoch 9/50\n1200/1200 [==============================] - 319s 265ms/step - loss: 0.0424 - accuracy: 0.9892 - val_loss: 0.0224 - val_accuracy: 0.9926\nEpoch 10/50\n1200/1200 [==============================] - 319s 266ms/step - loss: 0.0407 - accuracy: 0.9890 - val_loss: 0.0221 - val_accuracy: 0.9935\nEpoch 11/50\n1200/1200 [==============================] - 318s 265ms/step - loss: 0.0410 - accuracy: 0.9888 - val_loss: 0.0187 - val_accuracy: 0.9938\nEpoch 12/50\n1200/1200 [==============================] - 318s 265ms/step - loss: 0.0390 - accuracy: 0.9895 - val_loss: 0.0179 - val_accuracy: 0.9946\nEpoch 13/50\n1200/1200 [==============================] - 319s 265ms/step - loss: 0.0341 - accuracy: 0.9906 - val_loss: 0.0242 - val_accuracy: 0.9925\nEpoch 14/50\n1200/1200 [==============================] - 319s 266ms/step - loss: 0.0333 - accuracy: 0.9902 - val_loss: 0.0195 - val_accuracy: 0.9937\nEpoch 15/50\n1200/1200 [==============================] - 320s 266ms/step - loss: 0.0317 - accuracy: 0.9908 - val_loss: 0.0181 - val_accuracy: 0.9940\nEpoch 16/50\n 700/1200 [================>.............] - ETA: 2:08 - loss: 0.0289 - accuracy: 0.9919","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-5e56464090e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlr_schedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"#  Both have almost the same convergence time with max val accuracy of above 99%. The pretrained ones accuracy reached upto 99.46% and the one trained from scrach reached upto 99.50% in first 15 epochs.","metadata":{}}]}